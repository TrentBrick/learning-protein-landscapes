{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/Users/trentonbricken/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/trentonbricken/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/trentonbricken/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/trentonbricken/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/trentonbricken/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/trentonbricken/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rcParams\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "#tf.enable_eager_execution()\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1, '/Users/trentonbricken/protein-generators/deep_boltzmann/deep_boltzmann')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/trentonbricken/protein-generators/notebooks'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PlottingFunctions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "rcParams.update({'font.size': 16})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%load_ext autoreload\n",
    "#%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('../deep_boltzmann')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deep_boltzmann.networks.invertible import create_NICERNet, create_RealNVPNet, invnet\n",
    "from deep_boltzmann.sampling import GaussianPriorMCMC\n",
    "from deep_boltzmann.networks.plot import test_xz_projection\n",
    "from deep_boltzmann.util import count_transitions\n",
    "from deep_boltzmann.sampling.analysis import free_energy_bootstrap, mean_finite, std_finite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pylab as plt\n",
    "from scipy.special import softmax\n",
    "\n",
    "AA_num=20 # ignoring spaces here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from EVCouplingsGen import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the EVCouplings model\n",
    "\n",
    "I need to find a way to make this tensorflow friendly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evcouplings.couplings import CouplingsModel\n",
    "from EVCouplingsStuff.seq_sele import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/trentonbricken/protein-generators/deep_boltzmann'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "focus_seqs = read_fa('deep_boltzmann/EVCouplingsStuff/DYR_ECOLI_1_b0.5.a2m_trimmed.fa')\n",
    "evc_model = CouplingsModel('deep_boltzmann/EVCouplingsStuff/DYR.model')\n",
    "scores = evc_model.hamiltonians(list(focus_seqs['seq']))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'A': 0,\n",
       " 'C': 1,\n",
       " 'D': 2,\n",
       " 'E': 3,\n",
       " 'F': 4,\n",
       " 'G': 5,\n",
       " 'H': 6,\n",
       " 'I': 7,\n",
       " 'K': 8,\n",
       " 'L': 9,\n",
       " 'M': 10,\n",
       " 'N': 11,\n",
       " 'P': 12,\n",
       " 'Q': 13,\n",
       " 'R': 14,\n",
       " 'S': 15,\n",
       " 'T': 16,\n",
       " 'V': 17,\n",
       " 'W': 18,\n",
       " 'Y': 19}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evc_model.alphabet_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>header</th>\n",
       "      <th>seq</th>\n",
       "      <th>seq_ID</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DYR_ECOLI/1-159</td>\n",
       "      <td>SLIAALAVDRVIGMENAMPWNLPADLAWFKRNTLNKPVIMGRHTWE...</td>\n",
       "      <td>DYR_ECOLI/1-159</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>UniRef100_R7UK12/6-185</td>\n",
       "      <td>NLVVAACTNKGIGVDGRLPWTIRGDMAFFRKITSENVVLMGRKTWE...</td>\n",
       "      <td>UniRef100_R7UK12/6-185</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>UniRef100_T1G9P0/5-182</td>\n",
       "      <td>QIIVALCKNRGIGLNNSIPWKLPGDMTFFRKLTSENAILMGRKTWD...</td>\n",
       "      <td>UniRef100_T1G9P0/5-182</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>UniRef100_UPI0009BA7A0F/1-159</td>\n",
       "      <td>SLMWAMDENGVIGKDNQLPWHLPEDLKFFKRTTMGRPIVMGRKTWD...</td>\n",
       "      <td>UniRef100_UPI0009BA7A0F/1-159</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>UniRef100_UPI0002897BAD/1-159</td>\n",
       "      <td>SFIFAMDANRLIGKDNDLPWHLPNDLAYFKKVTSGHSIIMGRKTYE...</td>\n",
       "      <td>UniRef100_UPI0002897BAD/1-159</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          header  \\\n",
       "0                DYR_ECOLI/1-159   \n",
       "1         UniRef100_R7UK12/6-185   \n",
       "2         UniRef100_T1G9P0/5-182   \n",
       "3  UniRef100_UPI0009BA7A0F/1-159   \n",
       "4  UniRef100_UPI0002897BAD/1-159   \n",
       "\n",
       "                                                 seq  \\\n",
       "0  SLIAALAVDRVIGMENAMPWNLPADLAWFKRNTLNKPVIMGRHTWE...   \n",
       "1  NLVVAACTNKGIGVDGRLPWTIRGDMAFFRKITSENVVLMGRKTWE...   \n",
       "2  QIIVALCKNRGIGLNNSIPWKLPGDMTFFRKLTSENAILMGRKTWD...   \n",
       "3  SLMWAMDENGVIGKDNQLPWHLPEDLKFFKRTTMGRPIVMGRKTWD...   \n",
       "4  SFIFAMDANRLIGKDNDLPWHLPNDLAYFKKVTSGHSIIMGRKTYE...   \n",
       "\n",
       "                          seq_ID species  \n",
       "0                DYR_ECOLI/1-159    None  \n",
       "1         UniRef100_R7UK12/6-185    None  \n",
       "2         UniRef100_T1G9P0/5-182    None  \n",
       "3  UniRef100_UPI0009BA7A0F/1-159    None  \n",
       "4  UniRef100_UPI0002897BAD/1-159    None  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "focus_seqs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating weights and identities\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(7848, 155, 20)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc_seqs=[]\n",
    "for seq in focus_seqs['seq']:\n",
    "    enc_seqs.append(encode_aa(seq, evc_model.alphabet_map)) \n",
    "\n",
    "enc_seqs = np.asarray(enc_seqs)\n",
    "target_seq = enc_seqs[0]#encode_aa(np.char.upper(ali.matrix[0, :]), a2n)\n",
    "\n",
    "oh = []\n",
    "oh_flat = []\n",
    "N=20 # none of these focus have gaps, else should be 21. \n",
    "for seq in enc_seqs:\n",
    "    o = onehot(seq,N)\n",
    "    oh.append(o)\n",
    "    oh_flat.append(o.flatten())\n",
    "oh=np.asarray(oh)\n",
    "oh_flat=np.asarray(oh_flat)\n",
    "print('calculating weights and identities')\n",
    "N = oh.shape[0]\n",
    "L = oh.shape[1]\n",
    "AA = oh.shape[2]\n",
    "w, neighbors = msa_weights(enc_seqs, theta=0.8, pseudocount=0)\n",
    "oh.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7848, 155)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc_seqs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(155, 20)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h = evc_model.h_i\n",
    "h.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(155, 20)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_oh = oh[0]\n",
    "t_oh.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3100,)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_oh_flat =t_oh.flatten()\n",
    "t_oh_flat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3100,)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_oh_flat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = deepcopy(evc_model.J_ij)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(155, 155, 20, 20)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3100, 3100)\n"
     ]
    }
   ],
   "source": [
    "B = A.transpose(0,2,1,3)\n",
    "C = B.reshape(155*20,155*20)\n",
    "print(C.shape)\n",
    "J = torch.Tensor(C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6,)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_aa_seqs = focus_seqs.loc[0:5, 'seq']\n",
    "batch_aa_seqs = np.asarray(batch_aa_seqs)\n",
    "batch_aa_seqs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 3100])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_oh_flat = torch.Tensor(oh_flat[0:5,:])\n",
    "batch_oh_flat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[691.78837246 164.79214785 526.99622461]]\n",
      "[[616.32432526 146.38899448 469.93533077]]\n",
      "[[609.8757413 137.3846627 472.4910786]]\n",
      "[[675.83674874 124.9098807  550.92686803]]\n",
      "[[668.12467203 117.67201034 550.45266169]]\n",
      "[[667.23208667 116.96387957 550.2682071 ]]\n"
     ]
    }
   ],
   "source": [
    "for aa in batch_aa_seqs:\n",
    "    print( evc_model.hamiltonians([aa]) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3100, 3100])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "J.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3100])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h_flat = torch.Tensor(h).flatten()\n",
    "h_flat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([526.9962, 469.9354, 472.4911, 550.9269, 550.4527])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# got the h component\n",
    "torch.matmul(batch_oh_flat, h_flat )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([691.7883, 616.3243, 609.8757, 675.8368, 668.1247])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# batch oh flat must be of dimension: batch x (AA*len). J must be (AA*len)x(AA*len) and ensure that it is reshaped in the right way! (check diagonal is all zeros)\n",
    "((batch_oh_flat * (torch.matmul(batch_oh_flat, J))).sum(-1) /2) + torch.matmul(batch_oh_flat, h_flat )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## now seeing if this works for a softmax!! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "shape = (3,2,20)\n",
    "m = torch.distributions.Dirichlet(torch.tensor(np.ones(shape)*0.5), 5)\n",
    "sm = m.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 40])"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sm = sm.reshape(shape[0], shape[1]*shape[2])\n",
    "sm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2.0000, 2.0000, 2.0000], dtype=torch.float64)"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sm.sum(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([40, 40])"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "J_test = torch.Tensor(np.random.normal(10,10,(2,20,2,20))).double()\n",
    "J_test = ( J_test + J_test.transpose(0, 2).transpose(1,3) ) /2\n",
    "J_test[torch.arange(J_test.shape[0]),:,torch.arange(J_test.shape[0]),:] = 0\n",
    "J_test = J_test.reshape(2*20, 2*20)\n",
    "J_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[True, True, True,  ..., True, True, True],\n",
       "        [True, True, True,  ..., True, True, True],\n",
       "        [True, True, True,  ..., True, True, True],\n",
       "        ...,\n",
       "        [True, True, True,  ..., True, True, True],\n",
       "        [True, True, True,  ..., True, True, True],\n",
       "        [True, True, True,  ..., True, True, True]])"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "J_test == J_test.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(8.5259, dtype=torch.float64)"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "J_test[0,-1] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(8.5259, dtype=torch.float64)"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "J_test[-1,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([40])"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h_test = torch.Tensor(np.random.normal(5,10,(40))).double()\n",
    "h_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mat_evh(data):\n",
    "    data=data.double()\n",
    "    #print(torch.matmul(data, J_test))\n",
    "    return ((data * (torch.matmul(data, J_test))).sum(-1) /2) + torch.matmul(data, h_test )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 40, 40]) tensor(2400) tensor(59.2231, dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "print(xJx_batch.shape, (xJx_batch != 0).sum(), xJx_batch.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ind: 0 value tensor(26.3505, dtype=torch.float64)\n",
      "ind: 1 value tensor(26.8892, dtype=torch.float64)\n",
      "ind: 2 value tensor(19.0263, dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "# getting the true values by calculating each one. \n",
    "I = np.eye(20)\n",
    "for ind in range(3):\n",
    "    oh_sm = sm[ind,:].reshape(2,20) #.softmax(-1)\n",
    "    s = 0\n",
    "    sum_of_probs=0\n",
    "    for i in range(20):\n",
    "        for j in range(20):\n",
    "            to_test = torch.Tensor(np.hstack([I[i,:], I[j,:]]) )\n",
    "            sum_of_probs += (oh_sm[0,i]*oh_sm[1,j])\n",
    "            v = mat_evh(to_test)\n",
    "            s += v * (oh_sm[0,i]*oh_sm[1,j]) # val x prob of it being drawn. \n",
    "    print('ind:',ind, 'value', s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 40])"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 20])"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oh_sm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.0000, dtype=torch.float64)"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum_of_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([26.3505, 26.8892, 19.0263], dtype=torch.float64)"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_batch = deepcopy(sm)\n",
    "xJ_batch = torch.einsum('nl,lk->nlk', x_batch, J_test)\n",
    "# transpose all but the batch! \n",
    "# at this point it is no longer symmetric. \n",
    "xJx_batch = torch.einsum('nl,nlk->nlk', x_batch, xJ_batch.transpose(-1, -2))\n",
    "o = xJx_batch.sum(axis=(-1,-2))/2 + torch.einsum('nl,l->n', x_batch, h_test)\n",
    "o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([26.3505, 26.8892, 19.0263], dtype=torch.float64)"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat_evh(x_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[True, True, True,  ..., True, True, True],\n",
       "        [True, True, True,  ..., True, True, True],\n",
       "        [True, True, True,  ..., True, True, True],\n",
       "        ...,\n",
       "        [True, True, True,  ..., True, True, True],\n",
       "        [True, True, True,  ..., True, True, True],\n",
       "        [True, True, True,  ..., True, True, True]])"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "J_test == J_test.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(26.3260, dtype=torch.float64)"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "J_test[5,39]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(26.3260, dtype=torch.float64)"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "J_test[39,5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.3954, dtype=torch.float64)"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xJ_batch[0,5,30] #== xJ_batch.transpose(-1, -2)[0,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0346, dtype=torch.float64)"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xJ_batch.transpose(-1, -2)[0,-5,-30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 3.],\n",
       "        [2., 4.]])"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.Tensor(np.array([[1,2],[3,4]])).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 3.],\n",
       "        [2., 4.]])"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.Tensor(np.array([[1,2],[3,4]])).transpose(-1, -2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(26.3505, dtype=torch.float64)"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_batch = deepcopy(sm[0])\n",
    "(x_batch.T@J_test@x_batch).sum()/2 + torch.matmul(x_batch, h_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 40, 40])"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xJ_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(26.3505, dtype=torch.float64)"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xJ_batch = torch.einsum('l,lk->lk', x_batch, J_test)\n",
    "xJx_batch = torch.einsum('l,lk->lk', x_batch, xJ_batch.T)\n",
    "o = xJx_batch.sum(axis=(-1,-2))/2 +  x_batch@h_test\n",
    "o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ True,  True,  True,  ..., False, False, False],\n",
       "        [ True,  True,  True,  ..., False, False, False],\n",
       "        [ True,  True,  True,  ..., False, False, False],\n",
       "        ...,\n",
       "        [False, False, False,  ...,  True,  True,  True],\n",
       "        [False, False, False,  ...,  True,  True,  True],\n",
       "        [False, False, False,  ...,  True,  True,  True]])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([40])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2., dtype=torch.float64)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(x_batch.T*torch.eye(40).double()*torch.ones((40,1)).double()).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NLL = torch.matmul(x,Jsym) # broadcasting. THIS IS FOR ANY AA a AT POSITION p WHAT THE MATCHING SEQUENCE CONVERSION PENALTY/BONUS IS. \n",
    "        # PAIRWISE WITH EVERYTHING ELSE IN THE WHOLE SEQUENCE. EVEN IF THE THING ISNT THERE. PAIRWISE INTERACTION WITH WHAT IS THERE. \n",
    "        # ADD H TO EVERYTHING EVEN IF IT ISNT PRESENT THERE. \n",
    "        # *** BASICALLY WHAT SHOULD BE THERE GIVEN ALL OF THE OTHER INTERACTIONS AND THE SINGLETON VALUE THAT IS THERE??? \n",
    "        NLL = NLL.view(batch_size,L,AA).log_softmax(-1).view(batch_size,L*AA) #CONVERT TO SOFTMAXES.\n",
    "        # SOFTMAX IS TRYING TO PREDICT AT EACH POSITION WHAT THE AMNO ACID IS. \n",
    "\n",
    "        # weights include in batch draw frequency- to include would be w[batch]*x\n",
    "        NLL = -((x_one_hot_mask*NLL).sum(-1)).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "to dos. Get this working for a batch of sequences and have it work for a weighted sequence too. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(164.7921)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "J = torch.Tensor(C)\n",
    "plt.imshow(((flat_tens*J).T*(flat_tens) != 0))\n",
    "plt.gcf().set_size_inches(10,10)\n",
    "print(((flat_tens*J).T*(flat_tens)).sum()/2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
