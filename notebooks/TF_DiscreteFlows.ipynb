{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import edward2 as ed\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import multivariate_normal\n",
    "import tensorflow_probability as tfp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.0.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_samps = 50\n",
    "\n",
    "means = np.array([[8,9], [2,1], [8,1], [2,9], [5,12], [5,0], [10, 5], [1.5,5]]) * 10\n",
    "data = np.zeros((len(means)*n_samps,2))\n",
    "y = np.zeros((len(means)*n_samps,1))\n",
    "for ind, m in enumerate(means):\n",
    "    samps = multivariate_normal(m, np.eye(2)/0.1).rvs(n_samps).astype(int)\n",
    "    data[ind*n_samps:((ind+1)*n_samps)] = samps\n",
    "    y[ind*n_samps:((ind+1)*n_samps)] = np.tile(ind, n_samps).reshape(-1,1)\n",
    "    plt.scatter(samps[:,0], samps[:,1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400, 2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is converting all of the integers to onehots but this doesnt have to be the case. \n",
    "#need to change the base distribution and the data onehot conversion. \n",
    "\n",
    "batch_size, sequence_length, vocab_size = 32,  2, 150\n",
    "\n",
    "temperature = 0.1\n",
    "\n",
    "# Define the model.\n",
    "# , order='right-to-left' was on one of them but threw an error. \n",
    "units = vocab_size\n",
    "# hidden_dims=[64, 64]\n",
    "flow = tf.keras.Sequential([\n",
    "  ed.layers.DiscreteAutoregressiveFlow(ed.layers.MADE(vocab_size, hidden_dims=[64,64]), temperature),\n",
    "  ed.layers.DiscreteAutoregressiveFlow(ed.layers.MADE(vocab_size, hidden_dims=[64,64]), temperature),\n",
    "  ed.layers.DiscreteAutoregressiveFlow(ed.layers.MADE(vocab_size, hidden_dims=[64,64]), temperature),\n",
    "])\n",
    "\n",
    "# WHAT IS THE DIFFERENCE BETXWEEN A ONEHOT CATEGORICAL AND A NON ONEHOT CATEGORICAL? BEFORE I WAS GETTING ERRORS AND THE CATEGORICAL WAS WARPING MY DIMENSIONS\n",
    "\n",
    "# the probs for everything are distributed randomly accoring to a standard normal but they are then exponentiated. \n",
    "base = ed.OneHotCategorical(logits=tf.Variable(tf.random.normal([batch_size, sequence_length, vocab_size])), dtype=tf.float32)\n",
    "\n",
    "# Specify custom loss function and run training loop. Or use model.compile and\n",
    "# model.fit.\n",
    "\n",
    "'''def loss_fun(ground, passed):\n",
    "    \n",
    "    for l in reversed(flow.layers):\n",
    "        pass\n",
    "    \n",
    "    return tf.reduce_sum(tf.nn.softmax_cross_entropy_with_logits(labels=flow.reverse(features),\n",
    "          logits=model_rv.distribution.base.logits))'''\n",
    "\n",
    "def loss_fn(ground, passed):\n",
    "    '''print('features and then underscore', features,_)\n",
    "    temp = features\n",
    "    for l in flow.layers:\n",
    "        temp = l.reverse(temp)\n",
    "    whitened_features = temp #flow.reverse(features)\n",
    "    print('whitenend features', whitened_features )'''\n",
    "    # In this example, we don't include log-det-jacobian as in continuous flows.\n",
    "    # Discrete flows don't require them.\n",
    "    loss = -tf.reduce_mean(base.distribution.log_prob(passed))\n",
    "    print(loss)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0.]\n",
      "(400, 2, 150)\n"
     ]
    }
   ],
   "source": [
    "def one_hotter(x, depth):\n",
    "    idd = np.eye(depth)\n",
    "    print(idd[0])\n",
    "    res = np.zeros((x.shape[0], x.shape[1], depth))\n",
    "    print(res.shape)\n",
    "    for ind in range(len(x)): \n",
    "        for j, val in enumerate(x[ind]):\n",
    "            res[ind, j, :] = idd[int(val)]\n",
    "            \n",
    "    return res\n",
    "            \n",
    "\n",
    "oh = one_hotter(data, vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 2, 150)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oh[:batch_size, :, :].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer sequential_3 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "tf.Tensor(5.624161, shape=(), dtype=float32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=3435, shape=(), dtype=float32, numpy=5.624161>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_fn(0,flow(oh[:batch_size,:,:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#base.distribution.log_prob(oh[:batch_size, :, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this command here is buggy :/\n",
    "#tf.one_hot(data, depth=vocab_size, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 150\n",
      "(2, 1000)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(array([ 52.,  78., 150., 137., 116.,  72.,  83.,  73., 109., 130.]),\n",
       " array([  0. ,  14.9,  29.8,  44.7,  59.6,  74.5,  89.4, 104.3, 119.2,\n",
       "        134.1, 149. ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# example of the multinomail that should really be one hotted. \n",
    "tfd = tfp.distributions\n",
    "print(sequence_length, vocab_size)\n",
    "cat = tfd.Categorical(logits=tf.Variable(tf.random.normal([sequence_length, vocab_size])))\n",
    "s = tfd.Sample(\n",
    "    cat,\n",
    "    sample_shape=1000)\n",
    "x = s.sample()\n",
    "print(x.shape)\n",
    "plt.hist(x[0,:])\n",
    "plt.show()\n",
    "plt.hist(x[1,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def alt_loss_fn(features):\n",
    "    #print('features and then underscore', features)\n",
    "    whitened_features = flow_s.reverse(features) #flow.reverse(features)\n",
    "    #print('whitenend features', whitened_features )\n",
    "    # In this example, we don't include log-det-jacobian as in continuous flows.\n",
    "    # Discrete flows don't require them.\n",
    "    loss = -tf.reduce_mean(base.distribution.log_prob(whitened_features))\n",
    "    print('this is the loss',loss)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer discrete_autoregressive_flow_12 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=798409, shape=(32, 2, 150), dtype=float32, numpy=\n",
       "array([[[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 1.]],\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 1.]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [1., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 1., 0., ..., 0., 0., 0.]]], dtype=float32)>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flow_s(oh[:batch_size,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=798461, shape=(32, 2, 150), dtype=float32, numpy=\n",
       "array([[[-8.24530915e-08, -7.01892455e-09,  3.79447052e-08, ...,\n",
       "         -3.98574791e-08, -3.62204702e-08, -2.58645443e-08],\n",
       "        [-1.15235652e-08, -1.37591741e-07, -1.77923226e-07, ...,\n",
       "         -1.61436393e-08, -3.37019145e-07, -1.73112966e-07]],\n",
       "\n",
       "       [[ 3.21865095e-08, -3.80087677e-08,  9.93571376e-08, ...,\n",
       "          1.42955201e-07,  1.66220076e-07, -2.21102098e-07],\n",
       "        [-3.97364310e-08, -5.39880851e-08,  1.01881078e-07, ...,\n",
       "         -7.46040598e-08,  6.36336450e-09, -1.65533134e-08]],\n",
       "\n",
       "       [[-1.00334487e-08, -1.69801897e-08,  5.04879303e-08, ...,\n",
       "          1.66768913e-07, -2.02878834e-08, -1.00980010e-07],\n",
       "        [ 1.09275184e-08,  1.18134430e-07, -3.48332776e-08, ...,\n",
       "         -1.07304999e-07, -3.33523325e-08, -1.84815264e-07]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 3.21865095e-08, -3.80087677e-08,  9.93571376e-08, ...,\n",
       "          1.42955201e-07,  1.66220076e-07, -2.21102098e-07],\n",
       "        [-3.41733291e-08,  2.44787679e-09, -1.07295833e-07, ...,\n",
       "          5.20011803e-08,  1.62642912e-08, -3.83725265e-08]],\n",
       "\n",
       "       [[ 1.07288365e-08, -4.64756944e-08,  1.19493606e-07, ...,\n",
       "         -1.96028552e-07, -5.46877175e-08, -1.16999090e-07],\n",
       "        [-1.58945728e-08, -8.84793039e-09, -1.42397994e-07, ...,\n",
       "          8.59331237e-08,  1.20441896e-07, -1.37240264e-07]],\n",
       "\n",
       "       [[-2.98023224e-08, -9.96413192e-08,  7.39251149e-08, ...,\n",
       "         -5.72224845e-09, -7.47592566e-08,  2.91868893e-08],\n",
       "        [-6.19888354e-08, -3.02298631e-08, -3.25553884e-07, ...,\n",
       "          1.11435732e-07, -2.35346064e-07,  2.15956831e-07]]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flow_s.reverse(oh[:batch_size,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer made_12 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "network = ed.layers.MADE(vocab_size, hidden_dims=[64,64])\n",
    "flow_s = ed.layers.DiscreteAutoregressiveFlow(network, temperature)\n",
    "import copy\n",
    "opt = tf.keras.optimizers.Adam()\n",
    "epochs = 300\n",
    "@tf.function\n",
    "def train(model, dataset, optimizer, epochs=10):\n",
    "    \n",
    "    losses = []\n",
    "    for e in range(epochs):\n",
    "        if e%25==0:\n",
    "            print('epoch',e)\n",
    "        #passed = model(dataset[:batch_size,:,:])\n",
    "        model_rv = model(base)\n",
    "        with tf.GradientTape() as t:\n",
    "            \n",
    "            #current_loss = -tf.reduce_mean(base.distribution.log_prob(passed))\n",
    "            current_loss = tf.reduce_sum(tf.nn.softmax_cross_entropy_with_logits(\n",
    "                labels=model.reverse(dataset[:batch_size,:,:]),\n",
    "              logits=model_rv.distribution.base.logits)) #alt_loss_fn(oh[:batch_size])\n",
    "            #temp_loss = copy.deepcopy(current_loss)\n",
    "            losses.append(current_loss)\n",
    "        #print(current_loss)\n",
    "        gradients = t.gradient(current_loss, model.weights)\n",
    "        #print('GRADIENTS',gradients)\n",
    "        # zip(grads,network_.trainable_weights)\n",
    "        optimizer.apply_gradients(zip(gradients, model.weights))\n",
    "    return losses\n",
    "    \n",
    "losses = train(flow_s, oh,  opt, epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1a6c635650>]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=798483, shape=(32, 2, 150), dtype=float32, numpy=\n",
       "array([[[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]]], dtype=float32)>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x1a712b5690>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi40LCBodHRwOi8vbWF0cGxvdGxpYi5vcmcv7US4rQAAFeRJREFUeJzt3X+s3XV9x/Hna4XhBWMurLfY3ra71TBmsW4lJwTtYgi1KyqhTTNNnSzNNGmWMKdGkduRjOwP05vUqCSbWxpk1ElAgrU0ogJrR4hmwG6pWKDUdoLQ20qvw6qZN9jW9/443wunt+fcH+d7vud8zve8Hklzzvfz/Z5z3jl87/t8eX9+fBURmJlZef1epwMwM7NiOdGbmZWcE72ZWck50ZuZlZwTvZlZyTnRm5mVnBO9mVnJOdGbmZWcE72ZWcmd1+kAAObPnx9DQ0OdDsPMrKvs27fv5xExMNNxSST6oaEhRkdHOx2GmVlXkfTT2Rzn0o2ZWck50ZuZlZwTvZlZyTnRm5mVnBO9mVnJJTHqxlpr1/4xtj10iGMnJ1jU38fNay9n/crBTodlZh3iRF8yu/aPsWXnASZOnQFg7OQEW3YeAHCyN+tRLt2UzLaHDr2e5CdNnDrDtocOdSgiM+s0J/qSOXZyYk7tZlZ+Lt2UzKL+PsbqJPVF/X2Ffq77BczS5Sv6krl57eX0nT/vrLa+8+dx89rLC/vMyX6BsZMTBG/0C+zaP1bYZ5rZ7DnRl8z6lYNs3bCCwf4+BAz297F1w4pCr67dL2CWNpduOqiocsf6lYNtLZu4X8Asbb6i75AylTsa1f+L7hcws9mZMdFLulPSCUnP1Nn3WUkhaX5N2xZJRyQdkrS21QGXRZnKHZ3oFzCz2ZtN6eYu4J+Ar9U2SloCrAFeqmlbDmwErgAWAf8h6Y8i4uyMZqUqd0yWieZahvJIHbP2mDHRR8Rjkobq7PoS8DnggZq2dcC9EfEa8IKkI8BVwH/lD7VcOjUMsihz7RfwDF6z9mmqRi/pBmAsIp6esmsQeLlm+2jWZlP0ermjTKUrs9TNedSNpAuBW4E/r7e7Tls0eJ/NwGaApUuXzjWMrtdsuaMsylS6MktdM8Mr3w4sA56WBLAYeErSVVSv4JfUHLsYOFbvTSJiO7AdoFKp1P0xKLt2D4NMSdlKV2Ypm3PpJiIORMSCiBiKiCGqyf3KiPgZsBvYKOkCScuAy4AnWxqxlUKvl67q2bV/jFUje1k2/CCrRvZ25VBbS9OMV/SS7gGuAeZLOgrcFhFfrXdsRDwr6T7gOeA0cJNH3Fg9vV66msqd01YkRXS+alKpVGJ0dLTTYZh1zKqRvXVLWYP9ffxg+NoORGTdQNK+iKjMdJxnxpolwJ3TViQnerMEeBkJK5ITvVkC3DltRfLqlVY63bi0gjunrUhO9FYq3Tx6pZfnVVixXLqxUvHSCmbncqK3UvHoFbNzOdFbqXj0itm5nOitVDx6xexc7oy1UvHoFbNzOdFb6Xj0itnZXLoxMys5J3ozs5JzojczKzknejOzknOiNzMrOSd6M7OSc6I3Myu5GRO9pDslnZD0TE3bNknPS/qRpG9J6q/Zt0XSEUmHJK0tKnAzM5ud2VzR3wVcN6XtEeCdEfEu4MfAFgBJy4GNwBXZa74iaR5mZtYxMyb6iHgMeHVK28MRcTrbfBxYnD1fB9wbEa9FxAvAEeCqFsZrZmZz1Ioa/ceA72bPB4GXa/YdzdrMzKxDciV6SbcCp4G7J5vqHBYNXrtZ0qik0fHx8TxhmJnZNJpO9JI2AdcDH42IyWR+FFhSc9hi4Fi910fE9oioRERlYGCg2TDMzGwGTSV6SdcBtwA3RMRvanbtBjZKukDSMuAy4Mn8YZqZWbNmXKZY0j3ANcB8SUeB26iOsrkAeEQSwOMR8TcR8ayk+4DnqJZ0boqIM/Xf2czM2kFvVF06p1KpxOjoaKfDMDPrKpL2RURlpuM8M9bMrOSc6M3MSs6J3sys5JzozcxKzjcHN7OO2LV/jG0PHeLYyQkW9fdx89rLfVP3gjjRm1nb7do/xpadB5g4VR19PXZygi07DwA42RfApRsza7ttDx16PclPmjh1hm0PHepQROXmRG9mbXfs5MSc2i2fni3duD5o1jmL+vsYq5PUF/X3dSCa8uvJK/rJ+uDYyQmCN+qDu/aPdTo0s55w89rL6Tv/7HsS9Z0/j5vXXt6hiNpv1/4xVo3sZdnwg6wa2Vto/unJRO/6oFlnrV85yNYNKxjs70PAYH8fWzes6Jn/q273xWZPlm5cHzTrvPUrB3smsU813cVmEd9JT17RN6oDuj5oZu3Q7ovNnkz0rg+aWSe1+2KzJxN9r9cHzayz2n2x2ZM1eujt+qAVx8N2bTYmz4l2nSs9m+jNWs3T+m0u2nmx2ZOlG7MieNiupWrGRC/pTkknJD1T03aJpEckHc4eL67Zt0XSEUmHJK0tKnCz1HjYrqVqNlf0dwHXTWkbBvZExGXAnmwbScuBjcAV2Wu+ImkeZj3Aw3YtVTMm+oh4DHh1SvM6YEf2fAewvqb93oh4LSJeAI4AV7UoVrOkediuparZzthLI+I4QEQcl7Qgax8EHq857mjWZlZ67R5JYTZbrR51ozptUfdAaTOwGWDp0qUtDsOsMzxs11LU7KibVyQtBMgeT2TtR4ElNcctBo7Ve4OI2B4RlYioDAwMNBmGmZnNpNlEvxvYlD3fBDxQ075R0gWSlgGXAU/mC9HMzPKYsXQj6R7gGmC+pKPAbcAIcJ+kjwMvAR8CiIhnJd0HPAecBm6KiDN139jMzNpixkQfER9psGt1g+M/D3w+T1BmZtY6nhlrZlZyTvRmZiXnRG9mVnJO9GZmJedliq0reJ33xvzd2Eyc6C15Xue9MX83Nhsu3VjyvM57Y/5ubDac6C15Xue9MX83NhtO9JY8r/PemL8bmw0nepvRrv1jrBrZy7LhB1k1spdd+8fa+vle570xfzc2G+6MtWml0Nnndd4b83djs6GIusvFt1WlUonR0dFOh2F1rBrZy1ideu9gfx8/GL62AxGZ2SRJ+yKiMtNxvqLvEp0aK+3OPrPu5xp9F5gsn4ydnCB4o3zSjlq5O/vMup8TfRfo5Fhpd/aZdT+XbrpAJ8sn7uwz635O9F1gUX9f3Q7RdpVPfMNrs+7m0k0XcPnEzPLIleglfVrSs5KekXSPpDdJukTSI5IOZ48XtyrYXrV+5SBbN6xgsL8PUR3auHXDCl9lm9msND2OXtIg8H1geURMZDcF/w6wHHg1IkYkDQMXR8Qt072Xx9Gbmc1du8bRnwf0SToFXAgcA7YA12T7dwCPAtMmejOzTir7mv5Nl24iYgz4AvAScBz4ZUQ8DFwaEcezY44DC1oRqJlZETo5T6Vdmk70We19HbAMWARcJOnGObx+s6RRSaPj4+PNhmFmlksvrOmfpzP2fcALETEeEaeAncB7gFckLQTIHk/Ue3FEbI+ISkRUBgYGcoRhZta8XljmI0+ifwm4WtKFkgSsBg4Cu4FN2TGbgAfyhWhmVpxeWOYjT43+CeB+4CngQPZe24ERYI2kw8CabNvMLEm9ME8l16ibiLgNuG1K82tUr+57Wtl78c3KoheW+fASCAVI4WYdZjZ7ZV/mw0sgFKAXevHNrHs40RegF3rxzax7uHRTgE6vNmlmnZVaH52v6AvQC734ZlZfijNtnegL4NUmzXpXin10Lt0UpOy9+GZWX4p9dL6iNzNroRRn2jrRm5m1UIp9dC7dmJm1UIozbZ3ozcxaLLU+OpduzMxKzlf0VqjUJo6Y9SIneiuMF3czS4NLN1aYFCeOmPUiX9FbYVKcOGLl5TJhY76it8KkOHHEyinF9WVS4kRvhUlx4oiVk8uE08uV6CX1S7pf0vOSDkp6t6RLJD0i6XD2eHGrgrXu4sXdrF1cJpxe3hr97cD3IuIvJP0+cCHw98CeiBiRNAwMA7fk/BzrUqlNHLFy8j0gptf0Fb2ktwDvBb4KEBG/jYiTwDpgR3bYDmB93iDNzKbjMuH08pRu3gaMA/8mab+kOyRdBFwaEccBsscFLYjTzKwhlwmnl6d0cx5wJfCJiHhC0u1UyzSzImkzsBlg6dKlOcIwM3OZcDp5ruiPAkcj4ols+36qif8VSQsBsscT9V4cEdsjohIRlYGBgRxhmJnZdJpO9BHxM+BlSZNFsNXAc8BuYFPWtgl4IFeEZmaWS95RN58A7s5G3PwE+GuqPx73Sfo48BLwoZyfYWZmOeRK9BHxQ6BSZ9fqPO9rZmat45mxZmYl50RvZlZyXr1yFrwqnpl1Myf6GfjmGWbW7Vy6mYFXxTOzbudEPwOvimdm3c6lmxl4Vbze5b4Za1Zq546v6GfgVfF6k+9YZM1K8dxxop+BV8XrTe6bsWaleO64dDMLXhWv97hvxpqV4rnjK3qzOnxjc2tWiueOE71ZHan0zezaP8aqkb0sG36QVSN73UfQBVI5d2q5dGM2xeSIiYlTZ5gncSaCwQ6MnPBkve40+d8mpVE3TvRmNaYm1zMRr1+NtfsPdbpOPSf6tKXWr+fSjVmNlEZMpNipZ93Jid6sRkrJNcVOPetOTvRmNVJKril26ll3cqI3q5FScvVkPWuV3J2xkuYBo8BYRFwv6RLgG8AQ8CLw4Yj4Rd7PMWuH1EZMpNapZ92pFaNuPgkcBN6SbQ8DeyJiRNJwtn1LCz7HrC2cXK1scpVuJC0GPgjcUdO8DtiRPd8BrM/zGWZmlk/eGv2Xgc8Bv6tpuzQijgNkjwtyfoaZmeXQdKKXdD1wIiL2Nfn6zZJGJY2Oj483G4aZmc0gzxX9KuAGSS8C9wLXSvo68IqkhQDZ44l6L46I7RFRiYjKwMBAjjDMzGw6TSf6iNgSEYsjYgjYCOyNiBuB3cCm7LBNwAO5ozQzs6YVMY5+BFgj6TCwJts2M7MOacmiZhHxKPBo9vx/gdWteF8zM8vPM2PNzErOid7MrOSc6M3MSs6J3sys5JzozcxKzonezKzkfM9YM7NpTN4sPoVlq5vlRG9m1sDUm8WPnZxgy84DAF2V7F26MTNrIKWbxefhRG9m1kBKN4vPw4nezKyBlG4Wn4cTvZlZAyndLD6PUnTGlqFX3MzSk9rN4pvV9Ym+LL3iZpamMtwsvutLN2XpFTczK0rXJ/qy9IqbmRWl6xN9WXrFzcyK0vWJviy94mZmRen6ztiy9IqbmRWl6UQvaQnwNeCtwO+A7RFxu6RLgG8AQ8CLwIcj4hf5Q22sDL3iZmZFyVO6OQ18JiLeAVwN3CRpOTAM7ImIy4A92baZmXVI01f0EXEcOJ49/7Wkg8AgsA64JjtsB/AocEuuKK1neTKcWX4tqdFLGgJWAk8Al2Y/AkTEcUkLGrxmM7AZYOnSpa0Iw0rGk+HMWiP3qBtJbwa+CXwqIn4129dFxPaIqEREZWBgIG8YVkKeDGfWGrkSvaTzqSb5uyNiZ9b8iqSF2f6FwIl8IVqv8mQ4s9ZoOtFLEvBV4GBEfLFm125gU/Z8E/BA8+FZL/NkOLPWyHNFvwr4K+BaST/M/n0AGAHWSDoMrMm2zebMk+HMWiPPqJvvA2qwe3Wz72s2yZPhzFqj62fGWrl5MpxZfl2/1o2ZmU3Pid7MrOSc6M3MSs6J3sys5JzozcxKrudG3XiRLDPrNT2V6FNfJMs/QmZWhJ4q3aS8SNbkj9DYyQmCN36Edu0f63RoZtbleirRp7xIVso/QmbW3Xoq0ae8SFbKP0Jm1t16KtGnvEhWyj9CZtbdeirRr185yNYNKxjs70PAYH8fWzesSKLDM+UfITPrbj016gbSXSTLKzWaWVF6LtGnLNUfITPrbj1VujEz60VO9GZmJdfVpRvPJLV28vnWPv6uW6uwK3pJ10k6JOmIpOFWv79nklo7+XxrH3/XrVdIopc0D/hn4P3AcuAjkpa38jM8k9Tayedb+/i7br2iruivAo5ExE8i4rfAvcC6Vn6AZ5JaO/l8ax9/161XVKIfBF6u2T6atb1O0mZJo5JGx8fH5/wBnklq7eTzrX38XbdeUYleddrirI2I7RFRiYjKwMDAnD/AM0mtnXy+tY+/69YratTNUWBJzfZi4FgrP8AzSa2dfL61j7/r1lNEzHzUXN9UOg/4MbAaGAP+G/jLiHi23vGVSiVGR0dbHoeZWZlJ2hcRlZmOK+SKPiJOS/pb4CFgHnBnoyRvZmbFKmzCVER8B/hOUe9vZmaz4yUQzMxKzonezKzknOjNzEqukFE3cw5CGgd+2uk46pgP/LzTQcyB4y2W4y2W4527P4yIGSciJZHoUyVpdDZDl1LheIvleIvleIvj0o2ZWck50ZuZlZwT/fS2dzqAOXK8xXK8xXK8BXGN3sys5HxFb2ZWck70gKQlkv5T0kFJz0r6ZNZ+iaRHJB3OHi/udKy1JM2TtF/St7PtZOOV1C/pfknPZ9/zuxOP99PZufCMpHskvSm1eCXdKemEpGdq2hrGKGlLdmvPQ5LWJhLvtuyc+JGkb0nqTznemn2flRSS5te0dTTe6TjRV50GPhMR7wCuBm7Kbn04DOyJiMuAPdl2Sj4JHKzZTjne24HvRcQfA39CNe4k45U0CPwdUImId1JdmG8j6cV7F3DdlLa6MWbn80bgiuw1X8lu+dlOd3FuvI8A74yId1Fd8XYLJB0vkpYAa4CXatpSiLchJ3ogIo5HxFPZ819TTUKDVG9/uCM7bAewvjMRnkvSYuCDwB01zUnGK+ktwHuBrwJExG8j4iSJxps5D+jLlty+kOr9FJKKNyIeA16d0twoxnXAvRHxWkS8AByhesvPtqkXb0Q8HBGns83Hqd67AhKNN/Ml4HOcfTOljsc7HSf6KSQNASuBJ4BLI+I4VH8MgAWdi+wcX6Z6sv2upi3VeN8GjAP/lpWa7pB0EYnGGxFjwBeoXrEdB34ZEQ+TaLxTNIpxxtt7JuBjwHez50nGK+kGYCwinp6yK8l4JznR15D0ZuCbwKci4ledjqcRSdcDJyJiX6djmaXzgCuBf4mIlcD/0fmyR0NZXXsdsAxYBFwk6cbORpXbjLf37CRJt1Itod492VTnsI7GK+lC4FbgH+rtrtOWzPfrRJ+RdD7VJH93ROzMml+RtDDbvxA40an4plgF3CDpReBe4FpJXyfdeI8CRyPiiWz7fqqJP9V43we8EBHjEXEK2Am8h3TjrdUoxsJv79ksSZuA64GPxhvjvVOM9+1Uf/yfzv72FgNPSXoracb7Oid6QJKo1o8PRsQXa3btBjZlzzcBD7Q7tnoiYktELI6IIaodQHsj4kbSjfdnwMuSJu/uvBp4jkTjpVqyuVrShdm5sZpqv02q8dZqFONuYKOkCyQtAy4DnuxAfGeRdB1wC3BDRPymZldy8UbEgYhYEBFD2d/eUeDK7PxOLt6zRETP/wP+jOr/Zv0I+GH27wPAH1AduXA4e7yk07HWif0a4NvZ82TjBf4UGM2+413AxYnH+4/A88AzwL8DF6QWL3AP1T6EU1STzseni5Fq2eF/gEPA+xOJ9wjV2vbk392/phzvlP0vAvNTiXe6f54Za2ZWci7dmJmVnBO9mVnJOdGbmZWcE72ZWck50ZuZlZwTvZlZyTnRm5mVnBO9mVnJ/T+qVlZr/Y032QAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "rands = base.value\n",
    "rands_max = np.argmax(rands, axis=2)\n",
    "plt.scatter(rands_max[:,0], rands_max[:,1])\n",
    "plt.show()\n",
    "samps = flow_s(rands)\n",
    "samps = samps.numpy().argmax(axis=-1)\n",
    "plt.scatter( samps[:,0], samps[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "flow.compile(optimizer='adam',\n",
    "              loss=loss_fn)\n",
    "              #metrics=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"loss/output_1_loss/Neg:0\", shape=(), dtype=float32)\n",
      "Train on 400 samples\n",
      "Epoch 1/10\n",
      "Tensor(\"loss/output_1_loss/Neg:0\", shape=(), dtype=float32)\n",
      " 32/400 [=>............................] - ETA: 17s"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "No gradients provided for any variable: ['sequential_3/discrete_autoregressive_flow/made/sequential/dense/kernel:0', 'sequential_3/discrete_autoregressive_flow/made/sequential/dense/bias:0', 'sequential_3/discrete_autoregressive_flow/made/sequential/dense_1/kernel:0', 'sequential_3/discrete_autoregressive_flow/made/sequential/dense_1/bias:0', 'sequential_3/discrete_autoregressive_flow/made/sequential/dense_2/kernel:0', 'sequential_3/discrete_autoregressive_flow/made/sequential/dense_2/bias:0', 'sequential_3/discrete_autoregressive_flow_1/made_1/sequential_1/dense_3/kernel:0', 'sequential_3/discrete_autoregressive_flow_1/made_1/sequential_1/dense_3/bias:0', 'sequential_3/discrete_autoregressive_flow_1/made_1/sequential_1/dense_4/kernel:0', 'sequential_3/discrete_autoregressive_flow_1/made_1/sequential_1/dense_4/bias:0', 'sequential_3/discrete_autoregressive_flow_1/made_1/sequential_1/dense_5/kernel:0', 'sequential_3/discrete_autoregressive_flow_1/made_1/sequential_1/dense_5/bias:0', 'sequential_3/discrete_autoregressive_flow_2/made_2/sequential_2/dense_6/kernel:0', 'sequential_3/discrete_autoregressive_flow_2/made_2/sequential_2/dense_6/bias:0', 'sequential_3/discrete_autoregressive_flow_2/made_2/sequential_2/dense_7/kernel:0', 'sequential_3/discrete_autoregressive_flow_2/made_2/sequential_2/dense_7/bias:0', 'sequential_3/discrete_autoregressive_flow_2/made_2/sequential_2/dense_8/kernel:0', 'sequential_3/discrete_autoregressive_flow_2/made_2/sequential_2/dense_8/bias:0'].",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-dfbb1378298f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/ed2/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    727\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 728\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    729\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    730\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/anaconda3/envs/ed2/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    322\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 324\u001b[0;31m                 total_epochs=epochs)\n\u001b[0m\u001b[1;32m    325\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ed2/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[0;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[1;32m    121\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[1;32m    122\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ed2/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[0;34m(input_fn)\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[0;32m---> 86\u001b[0;31m                               distributed_function(input_fn))\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ed2/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_counter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalled_without_tracing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ed2/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    501\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    502\u001b[0m       \u001b[0minitializer_map\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobject_identity\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mObjectIdentityDictionary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 503\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializer_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    504\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    505\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ed2/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    406\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m    407\u001b[0m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0;32m--> 408\u001b[0;31m             *args, **kwds))\n\u001b[0m\u001b[1;32m    409\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    410\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minvalid_creator_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0munused_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0munused_kwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ed2/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1846\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_signature\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1847\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m     \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1849\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ed2/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   2148\u001b[0m         \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2149\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mgraph_function\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2150\u001b[0;31m           \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2151\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2152\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ed2/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   2039\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2040\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2041\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   2042\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2043\u001b[0m         \u001b[0;31m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ed2/lib/python3.7/site-packages/tensorflow_core/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    913\u001b[0m                                           converted_func)\n\u001b[1;32m    914\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ed2/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0;31m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 358\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    359\u001b[0m     \u001b[0mweak_wrapped_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweakref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapped_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ed2/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mdistributed_function\u001b[0;34m(input_iterator)\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0mstrategy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdistribution_strategy_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m     outputs = strategy.experimental_run_v2(\n\u001b[0;32m---> 73\u001b[0;31m         per_replica_function, args=(model, x, y, sample_weights))\n\u001b[0m\u001b[1;32m     74\u001b[0m     \u001b[0;31m# Out of PerReplica outputs reduce or pick values to return.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m     all_outputs = dist_utils.unwrap_output_dict(\n",
      "\u001b[0;32m~/anaconda3/envs/ed2/lib/python3.7/site-packages/tensorflow_core/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36mexperimental_run_v2\u001b[0;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[1;32m    758\u001b[0m       fn = autograph.tf_convert(fn, ag_ctx.control_status_ctx(),\n\u001b[1;32m    759\u001b[0m                                 convert_by_default=False)\n\u001b[0;32m--> 760\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extended\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    761\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    762\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ed2/lib/python3.7/site-packages/tensorflow_core/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36mcall_for_each_replica\u001b[0;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[1;32m   1785\u001b[0m       \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_container_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1787\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1788\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1789\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ed2/lib/python3.7/site-packages/tensorflow_core/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36m_call_for_each_replica\u001b[0;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[1;32m   2130\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_container_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2131\u001b[0m         replica_id_in_sync_group=constant_op.constant(0, dtypes.int32)):\n\u001b[0;32m-> 2132\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2134\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_reduce_to\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdestinations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ed2/lib/python3.7/site-packages/tensorflow_core/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    290\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mControlStatusCtx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDISABLED\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 292\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mismethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ed2/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(model, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[1;32m    262\u001b[0m       \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m       \u001b[0msample_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weights\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 264\u001b[0;31m       output_loss_metrics=model._output_loss_metrics)\n\u001b[0m\u001b[1;32m    265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ed2/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_eager.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(model, inputs, targets, sample_weights, output_loss_metrics)\u001b[0m\n\u001b[1;32m    309\u001b[0m           \u001b[0msample_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weights\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m           \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 311\u001b[0;31m           output_loss_metrics=output_loss_metrics))\n\u001b[0m\u001b[1;32m    312\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ed2/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_eager.py\u001b[0m in \u001b[0;36m_process_single_batch\u001b[0;34m(model, inputs, targets, output_loss_metrics, sample_weights, training)\u001b[0m\n\u001b[1;32m    270\u001b[0m                         loss_scale_optimizer.LossScaleOptimizer):\n\u001b[1;32m    271\u001b[0m             \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_unscaled_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 272\u001b[0;31m           \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainable_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    273\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m         logging.warning('The list of trainable weights is empty. Make sure that'\n",
      "\u001b[0;32m~/anaconda3/envs/ed2/lib/python3.7/site-packages/tensorflow_core/python/keras/optimizer_v2/optimizer_v2.py\u001b[0m in \u001b[0;36mapply_gradients\u001b[0;34m(self, grads_and_vars, name)\u001b[0m\n\u001b[1;32m    425\u001b[0m       \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIf\u001b[0m \u001b[0mnone\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mvariables\u001b[0m \u001b[0mhave\u001b[0m \u001b[0mgradients\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m     \"\"\"\n\u001b[0;32m--> 427\u001b[0;31m     \u001b[0mgrads_and_vars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_filter_grads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads_and_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    428\u001b[0m     \u001b[0mvar_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mv\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgrads_and_vars\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ed2/lib/python3.7/site-packages/tensorflow_core/python/keras/optimizer_v2/optimizer_v2.py\u001b[0m in \u001b[0;36m_filter_grads\u001b[0;34m(grads_and_vars)\u001b[0m\n\u001b[1;32m   1023\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfiltered\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1024\u001b[0m     raise ValueError(\"No gradients provided for any variable: %s.\" %\n\u001b[0;32m-> 1025\u001b[0;31m                      ([v.name for _, v in grads_and_vars],))\n\u001b[0m\u001b[1;32m   1026\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mvars_with_empty_grads\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1027\u001b[0m     logging.warning(\n",
      "\u001b[0;31mValueError\u001b[0m: No gradients provided for any variable: ['sequential_3/discrete_autoregressive_flow/made/sequential/dense/kernel:0', 'sequential_3/discrete_autoregressive_flow/made/sequential/dense/bias:0', 'sequential_3/discrete_autoregressive_flow/made/sequential/dense_1/kernel:0', 'sequential_3/discrete_autoregressive_flow/made/sequential/dense_1/bias:0', 'sequential_3/discrete_autoregressive_flow/made/sequential/dense_2/kernel:0', 'sequential_3/discrete_autoregressive_flow/made/sequential/dense_2/bias:0', 'sequential_3/discrete_autoregressive_flow_1/made_1/sequential_1/dense_3/kernel:0', 'sequential_3/discrete_autoregressive_flow_1/made_1/sequential_1/dense_3/bias:0', 'sequential_3/discrete_autoregressive_flow_1/made_1/sequential_1/dense_4/kernel:0', 'sequential_3/discrete_autoregressive_flow_1/made_1/sequential_1/dense_4/bias:0', 'sequential_3/discrete_autoregressive_flow_1/made_1/sequential_1/dense_5/kernel:0', 'sequential_3/discrete_autoregressive_flow_1/made_1/sequential_1/dense_5/bias:0', 'sequential_3/discrete_autoregressive_flow_2/made_2/sequential_2/dense_6/kernel:0', 'sequential_3/discrete_autoregressive_flow_2/made_2/sequential_2/dense_6/bias:0', 'sequential_3/discrete_autoregressive_flow_2/made_2/sequential_2/dense_7/kernel:0', 'sequential_3/discrete_autoregressive_flow_2/made_2/sequential_2/dense_7/bias:0', 'sequential_3/discrete_autoregressive_flow_2/made_2/sequential_2/dense_8/kernel:0', 'sequential_3/discrete_autoregressive_flow_2/made_2/sequential_2/dense_8/bias:0']."
     ]
    }
   ],
   "source": [
    "flow.fit(oh, y, epochs=10, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features and then underscore tf.Tensor(\n",
      "[[[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]], shape=(32, 2, 150), dtype=float32) 0\n",
      "whitenend features tf.Tensor(\n",
      "[[[ 4.39087557e-08 -1.16304342e-07  1.81788209e-07 ... -1.47833745e-07\n",
      "    4.70543888e-08 -1.89775903e-07]\n",
      "  [-4.76837165e-08  4.61427518e-08  1.74542024e-07 ... -1.25894772e-07\n",
      "    7.95030033e-08  5.46614096e-08]]\n",
      "\n",
      " [[-5.08268704e-06 -7.65686679e-08 -1.07436868e-07 ... -4.60467620e-09\n",
      "    1.02714985e-07 -8.60671676e-08]\n",
      "  [-1.48614248e-07 -3.07907925e-07  8.86944008e-07 ... -8.70709016e-08\n",
      "   -8.00550204e-09  2.43305038e-07]]\n",
      "\n",
      " [[ 1.22189519e-07 -8.24203923e-08  7.32002192e-08 ... -3.71855791e-09\n",
      "   -4.41420234e-09 -6.77529144e-08]\n",
      "  [ 4.27961368e-07  5.86763491e-08 -1.89021648e-07 ...  3.27118990e-08\n",
      "    3.42697604e-08 -6.35871515e-08]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[-4.49021655e-08 -3.90040888e-08 -2.02621866e-08 ...  2.10560174e-07\n",
      "    1.01098308e-07  1.99560120e-07]\n",
      "  [ 1.00930535e-07 -9.10367106e-08 -2.78230132e-08 ... -1.66242017e-07\n",
      "    2.39627809e-07 -2.27517845e-07]]\n",
      "\n",
      " [[-4.49021655e-08 -3.90040888e-08 -2.02621866e-08 ...  2.10560174e-07\n",
      "    1.01098308e-07  1.99560120e-07]\n",
      "  [ 1.44640609e-07 -1.27103192e-07 -6.23913436e-08 ... -4.64021035e-08\n",
      "    5.53045680e-08 -7.79338478e-08]]\n",
      "\n",
      " [[-2.05636024e-08 -2.52723055e-07  4.02106117e-08 ... -3.34373766e-07\n",
      "   -2.71300650e-07  7.75172396e-07]\n",
      "  [-2.59478895e-07 -6.88555915e-08  6.05335970e-07 ... -1.14320136e-08\n",
      "    3.93860189e-09  1.69304172e-07]]], shape=(32, 2, 150), dtype=float32)\n",
      "tf.Tensor(5.311535, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "out = flow(oh[:batch_size])\n",
    "loss = loss_fn(0, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features and then underscore Tensor(\"discrete_autoregressive_flow_6/concat_1:0\", shape=(32, 2, 150), dtype=float32) 0\n",
      "whitenend features Tensor(\"Real_2:0\", shape=(32, 2, 150), dtype=float32)\n",
      "Tensor(\"Neg:0\", shape=(), dtype=float32)\n",
      "GRADIENTS [None, None, None, None, None, None]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features and then underscore tf.Tensor(\n",
      "[[[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]], shape=(32, 2, 150), dtype=float32) 0\n",
      "whitenend features tf.Tensor(\n",
      "[[[ 4.39087557e-08 -1.16304342e-07  1.81788209e-07 ... -1.47833745e-07\n",
      "    4.70543888e-08 -1.89775903e-07]\n",
      "  [-4.76837165e-08  4.61427518e-08  1.74542024e-07 ... -1.25894772e-07\n",
      "    7.95030033e-08  5.46614096e-08]]\n",
      "\n",
      " [[-5.08268704e-06 -7.65686679e-08 -1.07436868e-07 ... -4.60467620e-09\n",
      "    1.02714985e-07 -8.60671676e-08]\n",
      "  [-1.48614248e-07 -3.07907925e-07  8.86944008e-07 ... -8.70709016e-08\n",
      "   -8.00550204e-09  2.43305038e-07]]\n",
      "\n",
      " [[ 1.22189519e-07 -8.24203923e-08  7.32002192e-08 ... -3.71855791e-09\n",
      "   -4.41420234e-09 -6.77529144e-08]\n",
      "  [ 4.27961368e-07  5.86763491e-08 -1.89021648e-07 ...  3.27118990e-08\n",
      "    3.42697604e-08 -6.35871515e-08]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[-4.49021655e-08 -3.90040888e-08 -2.02621866e-08 ...  2.10560174e-07\n",
      "    1.01098308e-07  1.99560120e-07]\n",
      "  [ 1.00930535e-07 -9.10367106e-08 -2.78230132e-08 ... -1.66242017e-07\n",
      "    2.39627809e-07 -2.27517845e-07]]\n",
      "\n",
      " [[-4.49021655e-08 -3.90040888e-08 -2.02621866e-08 ...  2.10560174e-07\n",
      "    1.01098308e-07  1.99560120e-07]\n",
      "  [ 1.44640609e-07 -1.27103192e-07 -6.23913436e-08 ... -4.64021035e-08\n",
      "    5.53045680e-08 -7.79338478e-08]]\n",
      "\n",
      " [[-2.05636024e-08 -2.52723055e-07  4.02106117e-08 ... -3.34373766e-07\n",
      "   -2.71300650e-07  7.75172396e-07]\n",
      "  [-2.59478895e-07 -6.88555915e-08  6.05335970e-07 ... -1.14320136e-08\n",
      "    3.93860189e-09  1.69304172e-07]]], shape=(32, 2, 150), dtype=float32)\n",
      "tf.Tensor(5.311535, shape=(), dtype=float32)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "`loss` passed to Optimizer.compute_gradients should be a function when eager execution is enabled.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-0de1ecd1975e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGradientDescentOptimizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mminimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/ed2/lib/python3.7/site-packages/tensorflow_core/python/training/optimizer.py\u001b[0m in \u001b[0;36mminimize\u001b[0;34m(self, loss, global_step, var_list, gate_gradients, aggregation_method, colocate_gradients_with_ops, name, grad_loss)\u001b[0m\n\u001b[1;32m    401\u001b[0m         \u001b[0maggregation_method\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maggregation_method\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m         \u001b[0mcolocate_gradients_with_ops\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolocate_gradients_with_ops\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 403\u001b[0;31m         grad_loss=grad_loss)\n\u001b[0m\u001b[1;32m    404\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    405\u001b[0m     \u001b[0mvars_with_grad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mv\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgrads_and_vars\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mg\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ed2/lib/python3.7/site-packages/tensorflow_core/python/training/optimizer.py\u001b[0m in \u001b[0;36mcompute_gradients\u001b[0;34m(self, loss, var_list, gate_gradients, aggregation_method, colocate_gradients_with_ops, grad_loss)\u001b[0m\n\u001b[1;32m    479\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    480\u001b[0m       raise RuntimeError(\n\u001b[0;32m--> 481\u001b[0;31m           \u001b[0;34m\"`loss` passed to Optimizer.compute_gradients should \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    482\u001b[0m           \"be a function when eager execution is enabled.\")\n\u001b[1;32m    483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: `loss` passed to Optimizer.compute_gradients should be a function when eager execution is enabled."
     ]
    }
   ],
   "source": [
    "optimizer = tf.compat.v1.train.GradientDescentOptimizer(learning_rate=0.1).minimize(loss_fn(0, out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(flow.trainable_variables())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 2\n",
    "length = 4\n",
    "loc_only=False\n",
    "vocab_size = 5\n",
    "if loc_only:\n",
    "    units = vocab_size\n",
    "    network = ed.layers.MADE(units, [])\n",
    "else:\n",
    "    units = 2 * vocab_size\n",
    "    mask = tf.reshape([0] * vocab_size + [-1e10] + [0] * (vocab_size - 1),\n",
    "                    [1, 1, 2 * vocab_size])\n",
    "    network_ = ed.layers.MADE(units, [])\n",
    "    network = lambda inputs, **kwargs: mask + network_(inputs, **kwargs)\n",
    "base = ed.OneHotCategorical(logits=tf.random.normal([batch_size,\n",
    "                                                     length,\n",
    "                                                     vocab_size]),\n",
    "                            dtype=tf.float32)\n",
    "flow = ed.layers.DiscreteAutoregressiveFlow(network, 1.)\n",
    "flow_rv = flow(base)\n",
    "\n",
    "\n",
    "#flow.evaluate(tf1.global_variables_initializer())\n",
    "#res = flow.evaluate(flow_rv)\n",
    "\n",
    "\n",
    "inputs = np.random.randint(0, vocab_size - 1, size=(batch_size, length))\n",
    "inputs = tf.one_hot(inputs, depth=vocab_size, dtype=tf.float32)\n",
    "outputs = flow(inputs)\n",
    "rev_outputs = flow.reverse(outputs)\n",
    "#inputs_val, rev_outputs_val = #([inputs, rev_outputs])\n",
    "\n",
    "\n",
    "inputs_log_prob = base.distribution.log_prob(inputs)\n",
    "outputs_log_prob = flow_rv.distribution.log_prob(outputs)\n",
    "#res1, res2 = self.evaluate([inputs_log_prob, outputs_log_prob])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'tensorflow.python.framework.ops.EagerTensor' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-e63d1744104c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     27\u001b[0m       logits=flow_rv.distribution.base.logits))\n\u001b[1;32m     28\u001b[0m \u001b[0;31m#grads = tape.gradient(loss, network_.trainable_weights)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mminimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnetwork_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m '''self.evaluate(tf1.global_variables_initializer())\n\u001b[1;32m     31\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ed2/lib/python3.7/site-packages/tensorflow_core/python/keras/optimizer_v2/optimizer_v2.py\u001b[0m in \u001b[0;36mminimize\u001b[0;34m(self, loss, var_list, grad_loss, name)\u001b[0m\n\u001b[1;32m    315\u001b[0m     \"\"\"\n\u001b[1;32m    316\u001b[0m     grads_and_vars = self._compute_gradients(\n\u001b[0;32m--> 317\u001b[0;31m         loss, var_list=var_list, grad_loss=grad_loss)\n\u001b[0m\u001b[1;32m    318\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads_and_vars\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ed2/lib/python3.7/site-packages/tensorflow_core/python/keras/optimizer_v2/optimizer_v2.py\u001b[0m in \u001b[0;36m_compute_gradients\u001b[0;34m(self, loss, var_list, grad_loss)\u001b[0m\n\u001b[1;32m    349\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    350\u001b[0m         \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 351\u001b[0;31m       \u001b[0mloss_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    352\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m       \u001b[0mvar_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvar_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'tensorflow.python.framework.ops.EagerTensor' object is not callable"
     ]
    }
   ],
   "source": [
    "batch_size = 2\n",
    "length = 4\n",
    "vocab_size = 2\n",
    "loc_only = True\n",
    "\n",
    "opt = tf.keras.optimizers.SGD(learning_rate=0.1)\n",
    "\n",
    "if loc_only:\n",
    "  units = vocab_size\n",
    "  network_ = ed.layers.MADE(units, [16, 16])\n",
    "  network = network_\n",
    "else:\n",
    "  units = 2 * vocab_size\n",
    "  network_ = ed.layers.MADE(units, [16, 16])\n",
    "  mask = tf.reshape([0] * vocab_size + [-1e10] + [0] * (vocab_size - 1),\n",
    "                    [1, 1, 2 * vocab_size])\n",
    "  network = lambda inputs, **kwargs: mask + network_(inputs, **kwargs)\n",
    "with tf.GradientTape() as tape:\n",
    "  base = ed.OneHotCategorical(\n",
    "      logits=tf.random.normal([batch_size, length, vocab_size]))\n",
    "  flow = ed.layers.DiscreteAutoregressiveFlow(network, 1.)\n",
    "  flow_rv = flow(base)\n",
    "  features = np.random.randint(0, vocab_size - 1, size=(batch_size, length))\n",
    "  features = tf.one_hot(features, depth=vocab_size, dtype=tf.float32)\n",
    "  loss = tf.reduce_sum(tf.nn.softmax_cross_entropy_with_logits(\n",
    "      labels=flow.reverse(features),\n",
    "      logits=flow_rv.distribution.base.logits))\n",
    "grads = tape.gradient(loss, network_.trainable_weights)\n",
    "opt.minimize(loss, network_.trainable_weights)\n",
    "'''self.evaluate(tf1.global_variables_initializer())\n",
    "_ = self.evaluate(grads)\n",
    "for grad in grads:\n",
    "  self.assertIsNotNone(grad)'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'UnreadVariable' shape=() dtype=int64, numpy=1>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "batch_size = 2\n",
    "length = 4\n",
    "vocab_size = 2\n",
    "loc_only = True\n",
    "\n",
    "opt = tf.keras.optimizers.SGD(learning_rate=0.1)\n",
    "\n",
    "if loc_only:\n",
    "  units = vocab_size\n",
    "  network_ = ed.layers.MADE(units, [16, 16])\n",
    "  network = network_\n",
    "else:\n",
    "  units = 2 * vocab_size\n",
    "  network_ = ed.layers.MADE(units, [16, 16])\n",
    "  mask = tf.reshape([0] * vocab_size + [-1e10] + [0] * (vocab_size - 1),\n",
    "                    [1, 1, 2 * vocab_size])\n",
    "  network = lambda inputs, **kwargs: mask + network_(inputs, **kwargs)\n",
    "    \n",
    "base = ed.OneHotCategorical(\n",
    "logits=tf.random.normal([batch_size, length, vocab_size]))\n",
    "flow = ed.layers.DiscreteAutoregressiveFlow(network, 1.)\n",
    "flow_rv = flow(base)\n",
    "features = np.random.randint(0, vocab_size - 1, size=(batch_size, length))\n",
    "features = tf.one_hot(features, depth=vocab_size, dtype=tf.float32)\n",
    "with tf.GradientTape() as tape:\n",
    "    loss = tf.reduce_sum(tf.nn.softmax_cross_entropy_with_logits(\n",
    "        labels=flow.reverse(features),\n",
    "        logits=flow_rv.distribution.base.logits))\n",
    "grads = tape.gradient(loss, network_.trainable_weights)\n",
    "opt.apply_gradients(zip(grads,network_.trainable_weights))\n",
    "#opt.minimize(loss, network_.trainable_weights)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=23497, shape=(2, 4), dtype=float32, numpy=\n",
       "array([[-4.1944447 , -1.7323816 , -0.9144609 , -3.8651865 ],\n",
       "       [-1.5306695 , -0.93880343, -2.4575806 , -1.8257781 ]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base.distribution.log_prob(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 4 5\n"
     ]
    }
   ],
   "source": [
    "print(batch_size,\n",
    "                                                     length,\n",
    "                                                     vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=23263, shape=(2, 4, 5), dtype=float32, numpy=\n",
       "array([[[ 3.57627883e-08,  5.22515613e-08,  1.02429908e-07,\n",
       "          9.99999702e-01,  1.19987362e-07],\n",
       "        [-3.57627883e-08,  6.89621649e-09,  9.99999821e-01,\n",
       "          8.45745518e-08,  5.60555691e-08],\n",
       "        [ 1.07288365e-07,  9.99999702e-01,  1.23809542e-07,\n",
       "         -1.26952484e-08,  1.49860625e-07],\n",
       "        [-3.57627883e-08,  6.89621649e-09,  9.99999821e-01,\n",
       "          8.45745518e-08,  5.60555691e-08]],\n",
       "\n",
       "       [[ 7.45058060e-08,  9.99999702e-01,  3.16178870e-08,\n",
       "          1.62374540e-08,  6.92420130e-08],\n",
       "        [ 3.57627883e-08,  5.22515613e-08,  1.02429908e-07,\n",
       "          9.99999702e-01,  1.19987362e-07],\n",
       "        [ 5.96046457e-09,  1.09662913e-07,  9.99999702e-01,\n",
       "          1.23093386e-07,  4.76912412e-08],\n",
       "        [ 5.06639495e-08,  9.99999821e-01, -6.92426727e-10,\n",
       "          1.56020747e-07,  1.22815225e-08]]], dtype=float32)>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rev_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=802826, shape=(150, 150), dtype=int32, numpy=\n",
       "array([[  0,   0,   0, ...,   0,   0,   0],\n",
       "       [  0,   1,   2, ..., 147, 148, 149],\n",
       "       [  0,   2,   4, ..., 144, 146, 148],\n",
       "       ...,\n",
       "       [  0, 147, 144, ...,   9,   6,   3],\n",
       "       [  0, 148, 146, ...,   6,   4,   2],\n",
       "       [  0, 149, 148, ...,   3,   2,   1]], dtype=int32)>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.math.floormod(\n",
    "        tf.tile(tf.range(vocab_size)[:, tf.newaxis], [1, vocab_size]) *\n",
    "        tf.range(vocab_size)[tf.newaxis], vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=802836, shape=(150, 150), dtype=int32, numpy=\n",
       "array([[  0,   0,   0, ...,   0,   0,   0],\n",
       "       [  1,   1,   1, ...,   1,   1,   1],\n",
       "       [  2,   2,   2, ...,   2,   2,   2],\n",
       "       ...,\n",
       "       [147, 147, 147, ..., 147, 147, 147],\n",
       "       [148, 148, 148, ..., 148, 148, 148],\n",
       "       [149, 149, 149, ..., 149, 149, 149]], dtype=int32)>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.tile(tf.range(vocab_size)[:, tf.newaxis], [1, vocab_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=802855, shape=(150, 150), dtype=int32, numpy=\n",
       "array([[    0,     0,     0, ...,     0,     0,     0],\n",
       "       [    0,     1,     2, ...,   147,   148,   149],\n",
       "       [    0,     2,     4, ...,   294,   296,   298],\n",
       "       ...,\n",
       "       [    0,   147,   294, ..., 21609, 21756, 21903],\n",
       "       [    0,   148,   296, ..., 21756, 21904, 22052],\n",
       "       [    0,   149,   298, ..., 21903, 22052, 22201]], dtype=int32)>"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.tile(tf.range(vocab_size)[:, tf.newaxis], [1, vocab_size]) * tf.range(vocab_size)[tf.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  0,   0,   0,  ...,   0,   0,   0],\n",
       "        [  1,   1,   1,  ...,   1,   1,   1],\n",
       "        [  2,   2,   2,  ...,   2,   2,   2],\n",
       "        ...,\n",
       "        [147, 147, 147,  ..., 147, 147, 147],\n",
       "        [148, 148, 148,  ..., 148, 148, 148],\n",
       "        [149, 149, 149,  ..., 149, 149, 149]])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.arange(vocab_size).unsqueeze(1).repeat(1,vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.arange(vocab_size).unsqueeze(1).repeat(1,vocab_size) * torch.arange(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[    0,     0,     0,  ...,     0,     0,     0],\n",
       "        [    0,     1,     2,  ...,   147,   148,   149],\n",
       "        [    0,     2,     4,  ...,   294,   296,   298],\n",
       "        ...,\n",
       "        [    0,   147,   294,  ..., 21609, 21756, 21903],\n",
       "        [    0,   148,   296,  ..., 21756, 21904, 22052],\n",
       "        [    0,   149,   298,  ..., 21903, 22052, 22201]])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def floorMod(a,b):\n",
    "    return a - (torch.floor(torch.div(a,b).float())*b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  0.,   0.,   0.,  ...,   0.,   0.,   0.],\n",
       "        [  0.,   1.,   2.,  ..., 147., 148., 149.],\n",
       "        [  0.,   2.,   4.,  ..., 144., 146., 148.],\n",
       "        ...,\n",
       "        [  0., 147., 144.,  ...,   9.,   6.,   3.],\n",
       "        [  0., 148., 146.,  ...,   6.,   4.,   2.],\n",
       "        [  0., 149., 148.,  ...,   3.,   2.,   1.]])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "floorMod(a, vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ed2",
   "language": "python",
   "name": "ed2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
