{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import edward2 as ed\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import multivariate_normal\n",
    "import tensorflow_probability as tfp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.0.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_samps = 50\n",
    "\n",
    "means = np.array([[8,9], [2,1], [8,1], [2,9], [5,12], [5,0], [10, 5], [1.5,5]]) * 10\n",
    "data = np.zeros((len(means)*n_samps,2))\n",
    "y = np.zeros((len(means)*n_samps,1))\n",
    "for ind, m in enumerate(means):\n",
    "    samps = multivariate_normal(m, np.eye(2)/0.1).rvs(n_samps).astype(int)\n",
    "    data[ind*n_samps:((ind+1)*n_samps)] = samps\n",
    "    y[ind*n_samps:((ind+1)*n_samps)] = np.tile(ind, n_samps).reshape(-1,1)\n",
    "    plt.scatter(samps[:,0], samps[:,1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400, 2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is converting all of the integers to onehots but this doesnt have to be the case. \n",
    "#need to change the base distribution and the data onehot conversion. \n",
    "\n",
    "batch_size, sequence_length, vocab_size = 32,  2, 150\n",
    "\n",
    "temperature = 0.1\n",
    "\n",
    "# Define the model.\n",
    "# , order='right-to-left' was on one of them but threw an error. \n",
    "units = vocab_size\n",
    "# hidden_dims=[64, 64]\n",
    "flow = tf.keras.Sequential([\n",
    "  ed.layers.DiscreteAutoregressiveFlow(ed.layers.MADE(vocab_size, hidden_dims=[64,64]), temperature),\n",
    "  ed.layers.DiscreteAutoregressiveFlow(ed.layers.MADE(vocab_size, hidden_dims=[64,64]), temperature),\n",
    "  ed.layers.DiscreteAutoregressiveFlow(ed.layers.MADE(vocab_size, hidden_dims=[64,64]), temperature),\n",
    "])\n",
    "\n",
    "# WHAT IS THE DIFFERENCE BETXWEEN A ONEHOT CATEGORICAL AND A NON ONEHOT CATEGORICAL? BEFORE I WAS GETTING ERRORS AND THE CATEGORICAL WAS WARPING MY DIMENSIONS\n",
    "\n",
    "# the probs for everything are distributed randomly accoring to a standard normal but they are then exponentiated. \n",
    "base = ed.OneHotCategorical(logits=tf.Variable(tf.random.normal([batch_size, sequence_length, vocab_size])), dtype=tf.float32)\n",
    "\n",
    "# Specify custom loss function and run training loop. Or use model.compile and\n",
    "# model.fit.\n",
    "\n",
    "'''def loss_fun(ground, passed):\n",
    "    \n",
    "    for l in reversed(flow.layers):\n",
    "        pass\n",
    "    \n",
    "    return tf.reduce_sum(tf.nn.softmax_cross_entropy_with_logits(labels=flow.reverse(features),\n",
    "          logits=model_rv.distribution.base.logits))'''\n",
    "\n",
    "def loss_fn(ground, passed):\n",
    "    '''print('features and then underscore', features,_)\n",
    "    temp = features\n",
    "    for l in flow.layers:\n",
    "        temp = l.reverse(temp)\n",
    "    whitened_features = temp #flow.reverse(features)\n",
    "    print('whitenend features', whitened_features )'''\n",
    "    # In this example, we don't include log-det-jacobian as in continuous flows.\n",
    "    # Discrete flows don't require them.\n",
    "    loss = -tf.reduce_mean(base.distribution.log_prob(passed))\n",
    "    print(loss)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=4134, shape=(32, 2, 150), dtype=bool, numpy=\n",
       "array([[[ True,  True,  True, ...,  True,  True,  True],\n",
       "        [ True,  True,  True, ...,  True,  True,  True]],\n",
       "\n",
       "       [[ True,  True,  True, ...,  True,  True,  True],\n",
       "        [ True,  True,  True, ...,  True,  True,  True]],\n",
       "\n",
       "       [[ True,  True,  True, ...,  True,  True,  True],\n",
       "        [ True,  True,  True, ...,  True,  True,  True]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ True,  True,  True, ...,  True,  True,  True],\n",
       "        [ True,  True,  True, ...,  True,  True,  True]],\n",
       "\n",
       "       [[ True,  True,  True, ...,  True,  True,  True],\n",
       "        [ True,  True,  True, ...,  True,  True,  True]],\n",
       "\n",
       "       [[ True,  True,  True, ...,  True,  True,  True],\n",
       "        [ True,  True,  True, ...,  True,  True,  True]]])>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(base).distribution.base.logits == base.distribution.logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'Variable:0' shape=(32, 2, 150) dtype=float32, numpy=\n",
       "array([[[ 0.99898505, -3.0071876 ,  0.9466668 , ..., -0.48307407,\n",
       "         -0.59963876,  0.13651057],\n",
       "        [-0.18276516,  0.94058913,  0.6285583 , ..., -1.2661057 ,\n",
       "         -0.41118056,  1.8518987 ]],\n",
       "\n",
       "       [[ 2.4963868 , -0.13002376,  2.110603  , ...,  2.1656876 ,\n",
       "          0.21204825,  0.3323681 ],\n",
       "        [ 0.62958723,  0.6910536 , -1.2692233 , ...,  1.282104  ,\n",
       "          0.607685  , -0.9027876 ]],\n",
       "\n",
       "       [[-0.48283204,  1.7185917 , -0.65634775, ..., -0.63169897,\n",
       "         -0.3940288 , -0.10424085],\n",
       "        [ 0.12355497,  1.2653755 ,  0.41304323, ..., -1.1233234 ,\n",
       "          0.9589236 ,  0.3922753 ]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 0.6264887 ,  0.11475684,  1.0336145 , ...,  0.3981701 ,\n",
       "         -0.1834339 ,  0.7487567 ],\n",
       "        [ 0.2978813 , -1.7587211 ,  1.2739275 , ..., -0.12416731,\n",
       "         -0.8823826 , -0.03147049]],\n",
       "\n",
       "       [[-0.17006683, -1.3160901 ,  0.9026324 , ..., -1.0118151 ,\n",
       "         -0.27005193,  0.87306637],\n",
       "        [ 0.96153575, -0.05574706,  0.7166574 , ...,  0.27540246,\n",
       "          1.4696295 , -0.4211306 ]],\n",
       "\n",
       "       [[ 0.44057846, -0.04244445,  0.6226099 , ..., -0.05713977,\n",
       "          0.57644105, -0.6726276 ],\n",
       "        [ 0.04183656, -0.32155707, -1.0495192 , ..., -1.8381839 ,\n",
       "         -1.989971  , -0.28689954]]], dtype=float32)>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base.distribution.logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0.]\n",
      "(400, 2, 150)\n"
     ]
    }
   ],
   "source": [
    "def one_hotter(x, depth):\n",
    "    idd = np.eye(depth)\n",
    "    print(idd[0])\n",
    "    res = np.zeros((x.shape[0], x.shape[1], depth))\n",
    "    print(res.shape)\n",
    "    for ind in range(len(x)): \n",
    "        for j, val in enumerate(x[ind]):\n",
    "            res[ind, j, :] = idd[int(val)]\n",
    "            \n",
    "    return res\n",
    "            \n",
    "\n",
    "oh = one_hotter(data, vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 2, 150)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oh[:batch_size, :, :].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer sequential_3 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "tf.Tensor(5.624161, shape=(), dtype=float32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=3435, shape=(), dtype=float32, numpy=5.624161>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_fn(0,flow(oh[:batch_size,:,:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#base.distribution.log_prob(oh[:batch_size, :, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this command here is buggy :/\n",
    "#tf.one_hot(data, depth=vocab_size, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 150\n",
      "(2, 1000)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(array([ 52.,  78., 150., 137., 116.,  72.,  83.,  73., 109., 130.]),\n",
       " array([  0. ,  14.9,  29.8,  44.7,  59.6,  74.5,  89.4, 104.3, 119.2,\n",
       "        134.1, 149. ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi40LCBodHRwOi8vbWF0cGxvdGxpYi5vcmcv7US4rQAAEEpJREFUeJzt3X+s3XV9x/Hna62iYAxlvUVscbeaRgWig9wQ1MUYkcGEUP4hKZGlmSTNEjbRaLQdycj+IGHR+OOP4dIA0kwCIYij8ddoqoYsmbALiAIFW4VBodLriD+mC1p974/zbXbsbnvvPedczulnz0dy8z3fz/f7Pd9X7u153W+/93y/J1WFJKldfzDuAJKk5WXRS1LjLHpJapxFL0mNs+glqXEWvSQ1zqKXpMZZ9JLUOItekhq3ctwBAFavXl3T09PjjiFJx5UHH3zwJ1U1tdB6E1H009PTzM7OjjuGJB1XkvzHYtbz1I0kNc6il6TGWfSS1DiLXpIaZ9FLUuMseklqnEUvSY2z6CWpcRa9JDVuIq6M1dJMb/3q2Pb99A0Xj23fkgbjEb0kNc6il6TGWfSS1DiLXpIaZ9FLUuMseklqnEUvSY2z6CWpcRa9JDVuwaJPckuSg0kenWfZx5JUktV9Y9uS7EvyZJILRx1YkrQ0izmivxW46MjBJKcDFwDP9I2dAWwCzuy2uTHJipEklSQNZMGir6r7gBfnWfQZ4ONA9Y1tBO6oqpeq6ilgH3DuKIJKkgYz0Dn6JJcCz1XVI0csWgs82ze/vxuTJI3Jku9emeRE4FrgT+dbPM9YzTNGki3AFoA3vOENS40hSVqkQY7o3wSsBx5J8jSwDngoyevoHcGf3rfuOuD5+Z6kqrZX1UxVzUxNTQ0QQ5K0GEsu+qr6flWtqarpqpqmV+7nVNWPgZ3ApiQnJFkPbAAeGGliSdKSLObtlbcD/wa8Ocn+JFcdbd2qegy4E3gc+AZwdVX9dlRhJUlLt+A5+qq6YoHl00fMXw9cP1wsTapxfbqVn2wlDc4rYyWpcRa9JDXOopekxln0ktQ4i16SGmfRS1LjLHpJapxFL0mNW/JNzSSpNeO6EBBenosBPaKXpMZZ9JLUOItekhpn0UtS4yx6SWqcRS9JjbPoJalxFr0kNc6il6TGLeYzY29JcjDJo31jn0zyRJLvJflykpP7lm1Lsi/Jk0kuXK7gkqTFWcwR/a3ARUeM7QLOqqq3AT8AtgEkOQPYBJzZbXNjkhUjSytJWrIFi76q7gNePGLs3qo61M1+B1jXPd4I3FFVL1XVU8A+4NwR5pUkLdEoztF/EPh693gt8Gzfsv3dmCRpTIYq+iTXAoeA2w4PzbNaHWXbLUlmk8zOzc0NE0OSdAwDF32SzcAlwAeq6nCZ7wdO71ttHfD8fNtX1faqmqmqmampqUFjSJIWMFDRJ7kI+ARwaVX9qm/RTmBTkhOSrAc2AA8MH1OSNKgFP3gkye3Ae4DVSfYD19F7l80JwK4kAN+pqr+sqseS3Ak8Tu+UztVV9dvlCi9JWtiCRV9VV8wzfPMx1r8euH6YUJKk0fHKWElqnJ8Zq+NC65/pKS0nj+glqXEWvSQ1zqKXpMZZ9JLUOItekhpn0UtS4yx6SWqcRS9JjfOCKUkTY5wXxrXMI3pJapxFL0mNs+glqXEWvSQ1zqKXpMZZ9JLUOItekhpn0UtS4xYs+iS3JDmY5NG+sVOS7Eqyt5uu6lu2Lcm+JE8muXC5gkuSFmcxR/S3AhcdMbYV2F1VG4Dd3TxJzgA2AWd229yYZMXI0kqSlmzBoq+q+4AXjxjeCOzoHu8ALusbv6OqXqqqp4B9wLkjyipJGsCg5+hPraoDAN10TTe+Fni2b7393ZgkaUxG/cfYzDNW866YbEkym2R2bm5uxDEkSYcNWvQvJDkNoJse7Mb3A6f3rbcOeH6+J6iq7VU1U1UzU1NTA8aQJC1k0KLfCWzuHm8G7ukb35TkhCTrgQ3AA8NFlCQNY8H70Se5HXgPsDrJfuA64AbgziRXAc8AlwNU1WNJ7gQeBw4BV1fVb5cpuyRpERYs+qq64iiLzj/K+tcD1w8TSpI0Ol4ZK0mNs+glqXEWvSQ1zqKXpMZZ9JLUOItekhpn0UtS4yx6SWqcRS9JjbPoJalxFr0kNc6il6TGWfSS1DiLXpIaZ9FLUuMseklqnEUvSY2z6CWpcQt+lKCk8Zje+tWx7fvpGy4e2741ekMd0Sf5SJLHkjya5PYkr0pySpJdSfZ201WjCitJWrqBiz7JWuBDwExVnQWsADYBW4HdVbUB2N3NS5LGZNhz9CuBVydZCZwIPA9sBHZ0y3cAlw25D0nSEAYu+qp6DvgU8AxwAPhZVd0LnFpVB7p1DgBr5ts+yZYks0lm5+bmBo0hSVrAMKduVtE7el8PvB44KcmVi92+qrZX1UxVzUxNTQ0aQ5K0gGFO3bwPeKqq5qrqN8DdwDuBF5KcBtBNDw4fU5I0qGHeXvkMcF6SE4H/Bs4HZoFfApuBG7rpPcOGnFTjfPubJC3WwEVfVfcnuQt4CDgEPAxsB14D3JnkKnq/DC4fRVBJ0mCGumCqqq4Drjti+CV6R/eSpAngLRAkqXEWvSQ1zqKXpMZZ9JLUOO9eKen/8K3DbbHopQVYejreeepGkhpn0UtS4yx6SWqcRS9JjbPoJalxFr0kNc6il6TGWfSS1DiLXpIaZ9FLUuMseklqnEUvSY0bquiTnJzkriRPJNmT5B1JTkmyK8nebrpqVGElSUs37BH954BvVNVbgLcDe4CtwO6q2gDs7uYlSWMycNEneS3wbuBmgKr6dVX9FNgI7OhW2wFcNmxISdLghjmifyMwB3whycNJbkpyEnBqVR0A6KZrRpBTkjSgYYp+JXAO8PmqOhv4JUs4TZNkS5LZJLNzc3NDxJAkHcswRb8f2F9V93fzd9Er/heSnAbQTQ/Ot3FVba+qmaqamZqaGiKGJOlYBi76qvox8GySN3dD5wOPAzuBzd3YZuCeoRJKkoYy7GfG/jVwW5JXAj8C/oLeL487k1wFPANcPuQ+JElDGKroq+q7wMw8i84f5nklSaPjlbGS1DiLXpIaZ9FLUuMseklqnEUvSY2z6CWpccO+j34iTG/96rgjSNLE8ohekhpn0UtS4yx6SWqcRS9JjbPoJalxFr0kNc6il6TGWfSS1DiLXpIaZ9FLUuMseklqnEUvSY0buuiTrEjycJKvdPOnJNmVZG83XTV8TEnSoEZxRH8NsKdvfiuwu6o2ALu7eUnSmAxV9EnWARcDN/UNbwR2dI93AJcNsw9J0nCGPaL/LPBx4Hd9Y6dW1QGAbrpmyH1IkoYwcNEnuQQ4WFUPDrj9liSzSWbn5uYGjSFJWsAwR/TvAi5N8jRwB/DeJF8EXkhyGkA3PTjfxlW1vapmqmpmampqiBiSpGMZuOiraltVrauqaWAT8M2quhLYCWzuVtsM3DN0SknSwJbjffQ3ABck2Qtc0M1LksZkJB8OXlXfBr7dPf5P4PxRPK8kaXheGStJjbPoJalxFr0kNc6il6TGWfSS1DiLXpIaZ9FLUuMseklqnEUvSY2z6CWpcRa9JDXOopekxln0ktQ4i16SGmfRS1LjLHpJapxFL0mNs+glqXEWvSQ1buCiT3J6km8l2ZPksSTXdOOnJNmVZG83XTW6uJKkpRrmiP4Q8NGqeitwHnB1kjOArcDuqtoA7O7mJUljMnDRV9WBqnqoe/wLYA+wFtgI7OhW2wFcNmxISdLgRnKOPsk0cDZwP3BqVR2A3i8DYM1RttmSZDbJ7Nzc3ChiSJLmMXTRJ3kN8CXgw1X188VuV1Xbq2qmqmampqaGjSFJOoqhij7JK+iV/G1VdXc3/EKS07rlpwEHh4soSRrGMO+6CXAzsKeqPt23aCewuXu8Gbhn8HiSpGGtHGLbdwF/Dnw/yXe7sb8BbgDuTHIV8Axw+XARJUnDGLjoq+pfgRxl8fmDPq8kabS8MlaSGmfRS1LjLHpJapxFL0mNs+glqXEWvSQ1zqKXpMZZ9JLUOItekhpn0UtS4yx6SWqcRS9JjbPoJalxFr0kNc6il6TGWfSS1DiLXpIaZ9FLUuOWreiTXJTkyST7kmxdrv1Iko5tWYo+yQrgH4A/A84ArkhyxnLsS5J0bMt1RH8usK+qflRVvwbuADYu074kScewXEW/Fni2b35/NyZJepmtXKbnzTxj9XsrJFuALd3sfyV5coj9rQZ+MsT2y23S84EZR8WMo/H/JmP+fqjN/2gxKy1X0e8HTu+bXwc8379CVW0Hto9iZ0lmq2pmFM+1HCY9H5hxVMw4GmYcreU6dfPvwIYk65O8EtgE7FymfUmSjmFZjuir6lCSvwL+BVgB3FJVjy3HviRJx7Zcp26oqq8BX1uu5z/CSE4BLaNJzwdmHBUzjoYZRyhVtfBakqTjlrdAkKTGHddFP4m3WUhyepJvJdmT5LEk13TjpyTZlWRvN1015pwrkjyc5CsTmu/kJHcleaL7Xr5jAjN+pPsZP5rk9iSvGnfGJLckOZjk0b6xo2ZKsq17/TyZ5MIxZvxk97P+XpIvJzl50jL2LftYkkqyepwZl+K4LfoJvs3CIeCjVfVW4Dzg6i7XVmB3VW0Adnfz43QNsKdvftLyfQ74RlW9BXg7vawTkzHJWuBDwExVnUXvTQebJiDjrcBFR4zNm6n7d7kJOLPb5sbudTWOjLuAs6rqbcAPgG0TmJEkpwMXAM/0jY0r46Idt0XPhN5moaoOVNVD3eNf0CuotfSy7ehW2wFcNp6EkGQdcDFwU9/wJOV7LfBu4GaAqvp1Vf2UCcrYWQm8OslK4ER614qMNWNV3Qe8eMTw0TJtBO6oqpeq6ilgH73X1cuesarurapD3ex36F17M1EZO58BPs7vXwA6loxLcTwX/cTfZiHJNHA2cD9walUdgN4vA2DN+JLxWXr/WH/XNzZJ+d4IzAFf6E4v3ZTkpEnKWFXPAZ+id2R3APhZVd07SRn7HC3TpL6GPgh8vXs8MRmTXAo8V1WPHLFoYjIezfFc9AveZmGckrwG+BLw4ar6+bjzHJbkEuBgVT047izHsBI4B/h8VZ0N/JLxn0r6Pd157o3AeuD1wElJrhxvqiWbuNdQkmvpnf687fDQPKu97BmTnAhcC/ztfIvnGZuYLoLju+gXvM3CuCR5Bb2Sv62q7u6GX0hyWrf8NODgmOK9C7g0ydP0Tne9N8kXJygf9H62+6vq/m7+LnrFP0kZ3wc8VVVzVfUb4G7gnROW8bCjZZqo11CSzcAlwAfqf9/3PSkZ30Tvl/oj3WtnHfBQktcxORmP6ngu+om8zUKS0Du3vKeqPt23aCewuXu8Gbjn5c4GUFXbqmpdVU3T+559s6qunJR8AFX1Y+DZJG/uhs4HHmeCMtI7ZXNekhO7n/n59P4eM0kZDztapp3ApiQnJFkPbAAeGEM+klwEfAK4tKp+1bdoIjJW1ferak1VTXevnf3AOd2/1YnIeExVddx+Ae+n9xf6HwLXjjtPl+lP6P237XvAd7uv9wN/SO8dD3u76SkTkPU9wFe6xxOVD/hjYLb7Pv4zsGoCM/4d8ATwKPBPwAnjzgjcTu9vBr+hV0ZXHSsTvdMRPwSeBP5sjBn30TvPffg184+TlvGI5U8Dq8eZcSlfXhkrSY07nk/dSJIWwaKXpMZZ9JLUOItekhpn0UtS4yx6SWqcRS9JjbPoJalx/wPjrzWGK8qOPAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# example of the multinomail that should really be one hotted. \n",
    "tfd = tfp.distributions\n",
    "print(sequence_length, vocab_size)\n",
    "cat = tfd.Categorical(logits=tf.Variable(tf.random.normal([sequence_length, vocab_size])))\n",
    "s = tfd.Sample(\n",
    "    cat,\n",
    "    sample_shape=1000)\n",
    "x = s.sample()\n",
    "print(x.shape)\n",
    "plt.hist(x[0,:])\n",
    "plt.show()\n",
    "plt.hist(x[1,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def alt_loss_fn(features):\n",
    "    #print('features and then underscore', features)\n",
    "    whitened_features = flow_s.reverse(features) #flow.reverse(features)\n",
    "    #print('whitenend features', whitened_features )\n",
    "    # In this example, we don't include log-det-jacobian as in continuous flows.\n",
    "    # Discrete flows don't require them.\n",
    "    loss = -tf.reduce_mean(base.distribution.log_prob(whitened_features))\n",
    "    print('this is the loss',loss)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer discrete_autoregressive_flow_12 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=798409, shape=(32, 2, 150), dtype=float32, numpy=\n",
       "array([[[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 1.]],\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 1.]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [1., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 1., 0., ..., 0., 0., 0.]]], dtype=float32)>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flow_s(oh[:batch_size,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=798461, shape=(32, 2, 150), dtype=float32, numpy=\n",
       "array([[[-8.24530915e-08, -7.01892455e-09,  3.79447052e-08, ...,\n",
       "         -3.98574791e-08, -3.62204702e-08, -2.58645443e-08],\n",
       "        [-1.15235652e-08, -1.37591741e-07, -1.77923226e-07, ...,\n",
       "         -1.61436393e-08, -3.37019145e-07, -1.73112966e-07]],\n",
       "\n",
       "       [[ 3.21865095e-08, -3.80087677e-08,  9.93571376e-08, ...,\n",
       "          1.42955201e-07,  1.66220076e-07, -2.21102098e-07],\n",
       "        [-3.97364310e-08, -5.39880851e-08,  1.01881078e-07, ...,\n",
       "         -7.46040598e-08,  6.36336450e-09, -1.65533134e-08]],\n",
       "\n",
       "       [[-1.00334487e-08, -1.69801897e-08,  5.04879303e-08, ...,\n",
       "          1.66768913e-07, -2.02878834e-08, -1.00980010e-07],\n",
       "        [ 1.09275184e-08,  1.18134430e-07, -3.48332776e-08, ...,\n",
       "         -1.07304999e-07, -3.33523325e-08, -1.84815264e-07]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 3.21865095e-08, -3.80087677e-08,  9.93571376e-08, ...,\n",
       "          1.42955201e-07,  1.66220076e-07, -2.21102098e-07],\n",
       "        [-3.41733291e-08,  2.44787679e-09, -1.07295833e-07, ...,\n",
       "          5.20011803e-08,  1.62642912e-08, -3.83725265e-08]],\n",
       "\n",
       "       [[ 1.07288365e-08, -4.64756944e-08,  1.19493606e-07, ...,\n",
       "         -1.96028552e-07, -5.46877175e-08, -1.16999090e-07],\n",
       "        [-1.58945728e-08, -8.84793039e-09, -1.42397994e-07, ...,\n",
       "          8.59331237e-08,  1.20441896e-07, -1.37240264e-07]],\n",
       "\n",
       "       [[-2.98023224e-08, -9.96413192e-08,  7.39251149e-08, ...,\n",
       "         -5.72224845e-09, -7.47592566e-08,  2.91868893e-08],\n",
       "        [-6.19888354e-08, -3.02298631e-08, -3.25553884e-07, ...,\n",
       "          1.11435732e-07, -2.35346064e-07,  2.15956831e-07]]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flow_s.reverse(oh[:batch_size,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer made_12 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "network = ed.layers.MADE(vocab_size, hidden_dims=[64,64])\n",
    "flow_s = ed.layers.DiscreteAutoregressiveFlow(network, temperature)\n",
    "import copy\n",
    "opt = tf.keras.optimizers.Adam()\n",
    "epochs = 300\n",
    "@tf.function\n",
    "def train(model, dataset, optimizer, epochs=10):\n",
    "    \n",
    "    losses = []\n",
    "    for e in range(epochs):\n",
    "        if e%25==0:\n",
    "            print('epoch',e)\n",
    "        #passed = model(dataset[:batch_size,:,:])\n",
    "        model_rv = model(base)\n",
    "        with tf.GradientTape() as t:\n",
    "            \n",
    "            #current_loss = -tf.reduce_mean(base.distribution.log_prob(passed))\n",
    "            current_loss = tf.reduce_sum(tf.nn.softmax_cross_entropy_with_logits(\n",
    "                labels=model.reverse(dataset[:batch_size,:,:]),\n",
    "              logits=model_rv.distribution.base.logits)) #alt_loss_fn(oh[:batch_size])\n",
    "            #temp_loss = copy.deepcopy(current_loss)\n",
    "            losses.append(current_loss)\n",
    "        #print(current_loss)\n",
    "        gradients = t.gradient(current_loss, model.weights)\n",
    "        #print('GRADIENTS',gradients)\n",
    "        # zip(grads,network_.trainable_weights)\n",
    "        optimizer.apply_gradients(zip(gradients, model.weights))\n",
    "    return losses\n",
    "    \n",
    "losses = train(flow_s, oh,  opt, epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1a6c635650>]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=798483, shape=(32, 2, 150), dtype=float32, numpy=\n",
       "array([[[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]]], dtype=float32)>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x1a712b5690>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "rands = base.value\n",
    "rands_max = np.argmax(rands, axis=2)\n",
    "plt.scatter(rands_max[:,0], rands_max[:,1])\n",
    "plt.show()\n",
    "samps = flow_s(rands)\n",
    "samps = samps.numpy().argmax(axis=-1)\n",
    "plt.scatter( samps[:,0], samps[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "flow.compile(optimizer='adam',\n",
    "              loss=loss_fn)\n",
    "              #metrics=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"loss/output_1_loss/Neg:0\", shape=(), dtype=float32)\n",
      "Train on 400 samples\n",
      "Epoch 1/10\n",
      "Tensor(\"loss/output_1_loss/Neg:0\", shape=(), dtype=float32)\n",
      " 32/400 [=>............................] - ETA: 17s"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "No gradients provided for any variable: ['sequential_3/discrete_autoregressive_flow/made/sequential/dense/kernel:0', 'sequential_3/discrete_autoregressive_flow/made/sequential/dense/bias:0', 'sequential_3/discrete_autoregressive_flow/made/sequential/dense_1/kernel:0', 'sequential_3/discrete_autoregressive_flow/made/sequential/dense_1/bias:0', 'sequential_3/discrete_autoregressive_flow/made/sequential/dense_2/kernel:0', 'sequential_3/discrete_autoregressive_flow/made/sequential/dense_2/bias:0', 'sequential_3/discrete_autoregressive_flow_1/made_1/sequential_1/dense_3/kernel:0', 'sequential_3/discrete_autoregressive_flow_1/made_1/sequential_1/dense_3/bias:0', 'sequential_3/discrete_autoregressive_flow_1/made_1/sequential_1/dense_4/kernel:0', 'sequential_3/discrete_autoregressive_flow_1/made_1/sequential_1/dense_4/bias:0', 'sequential_3/discrete_autoregressive_flow_1/made_1/sequential_1/dense_5/kernel:0', 'sequential_3/discrete_autoregressive_flow_1/made_1/sequential_1/dense_5/bias:0', 'sequential_3/discrete_autoregressive_flow_2/made_2/sequential_2/dense_6/kernel:0', 'sequential_3/discrete_autoregressive_flow_2/made_2/sequential_2/dense_6/bias:0', 'sequential_3/discrete_autoregressive_flow_2/made_2/sequential_2/dense_7/kernel:0', 'sequential_3/discrete_autoregressive_flow_2/made_2/sequential_2/dense_7/bias:0', 'sequential_3/discrete_autoregressive_flow_2/made_2/sequential_2/dense_8/kernel:0', 'sequential_3/discrete_autoregressive_flow_2/made_2/sequential_2/dense_8/bias:0'].",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-dfbb1378298f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/ed2/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    727\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 728\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    729\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    730\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/anaconda3/envs/ed2/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    322\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 324\u001b[0;31m                 total_epochs=epochs)\n\u001b[0m\u001b[1;32m    325\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ed2/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[0;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[1;32m    121\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[1;32m    122\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ed2/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[0;34m(input_fn)\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[0;32m---> 86\u001b[0;31m                               distributed_function(input_fn))\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ed2/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_counter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalled_without_tracing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ed2/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    501\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    502\u001b[0m       \u001b[0minitializer_map\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobject_identity\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mObjectIdentityDictionary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 503\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializer_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    504\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    505\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ed2/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    406\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m    407\u001b[0m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0;32m--> 408\u001b[0;31m             *args, **kwds))\n\u001b[0m\u001b[1;32m    409\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    410\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minvalid_creator_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0munused_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0munused_kwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ed2/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1846\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_signature\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1847\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m     \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1849\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ed2/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   2148\u001b[0m         \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2149\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mgraph_function\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2150\u001b[0;31m           \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2151\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2152\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ed2/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   2039\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2040\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2041\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   2042\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2043\u001b[0m         \u001b[0;31m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ed2/lib/python3.7/site-packages/tensorflow_core/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    913\u001b[0m                                           converted_func)\n\u001b[1;32m    914\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ed2/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0;31m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 358\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    359\u001b[0m     \u001b[0mweak_wrapped_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweakref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapped_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ed2/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mdistributed_function\u001b[0;34m(input_iterator)\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0mstrategy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdistribution_strategy_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m     outputs = strategy.experimental_run_v2(\n\u001b[0;32m---> 73\u001b[0;31m         per_replica_function, args=(model, x, y, sample_weights))\n\u001b[0m\u001b[1;32m     74\u001b[0m     \u001b[0;31m# Out of PerReplica outputs reduce or pick values to return.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m     all_outputs = dist_utils.unwrap_output_dict(\n",
      "\u001b[0;32m~/anaconda3/envs/ed2/lib/python3.7/site-packages/tensorflow_core/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36mexperimental_run_v2\u001b[0;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[1;32m    758\u001b[0m       fn = autograph.tf_convert(fn, ag_ctx.control_status_ctx(),\n\u001b[1;32m    759\u001b[0m                                 convert_by_default=False)\n\u001b[0;32m--> 760\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extended\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    761\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    762\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ed2/lib/python3.7/site-packages/tensorflow_core/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36mcall_for_each_replica\u001b[0;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[1;32m   1785\u001b[0m       \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_container_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1787\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1788\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1789\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ed2/lib/python3.7/site-packages/tensorflow_core/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36m_call_for_each_replica\u001b[0;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[1;32m   2130\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_container_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2131\u001b[0m         replica_id_in_sync_group=constant_op.constant(0, dtypes.int32)):\n\u001b[0;32m-> 2132\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2134\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_reduce_to\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdestinations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ed2/lib/python3.7/site-packages/tensorflow_core/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    290\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mControlStatusCtx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDISABLED\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 292\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mismethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ed2/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(model, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[1;32m    262\u001b[0m       \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m       \u001b[0msample_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weights\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 264\u001b[0;31m       output_loss_metrics=model._output_loss_metrics)\n\u001b[0m\u001b[1;32m    265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ed2/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_eager.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(model, inputs, targets, sample_weights, output_loss_metrics)\u001b[0m\n\u001b[1;32m    309\u001b[0m           \u001b[0msample_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weights\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m           \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 311\u001b[0;31m           output_loss_metrics=output_loss_metrics))\n\u001b[0m\u001b[1;32m    312\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ed2/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_eager.py\u001b[0m in \u001b[0;36m_process_single_batch\u001b[0;34m(model, inputs, targets, output_loss_metrics, sample_weights, training)\u001b[0m\n\u001b[1;32m    270\u001b[0m                         loss_scale_optimizer.LossScaleOptimizer):\n\u001b[1;32m    271\u001b[0m             \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_unscaled_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 272\u001b[0;31m           \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainable_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    273\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m         logging.warning('The list of trainable weights is empty. Make sure that'\n",
      "\u001b[0;32m~/anaconda3/envs/ed2/lib/python3.7/site-packages/tensorflow_core/python/keras/optimizer_v2/optimizer_v2.py\u001b[0m in \u001b[0;36mapply_gradients\u001b[0;34m(self, grads_and_vars, name)\u001b[0m\n\u001b[1;32m    425\u001b[0m       \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIf\u001b[0m \u001b[0mnone\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mvariables\u001b[0m \u001b[0mhave\u001b[0m \u001b[0mgradients\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m     \"\"\"\n\u001b[0;32m--> 427\u001b[0;31m     \u001b[0mgrads_and_vars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_filter_grads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads_and_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    428\u001b[0m     \u001b[0mvar_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mv\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgrads_and_vars\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ed2/lib/python3.7/site-packages/tensorflow_core/python/keras/optimizer_v2/optimizer_v2.py\u001b[0m in \u001b[0;36m_filter_grads\u001b[0;34m(grads_and_vars)\u001b[0m\n\u001b[1;32m   1023\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfiltered\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1024\u001b[0m     raise ValueError(\"No gradients provided for any variable: %s.\" %\n\u001b[0;32m-> 1025\u001b[0;31m                      ([v.name for _, v in grads_and_vars],))\n\u001b[0m\u001b[1;32m   1026\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mvars_with_empty_grads\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1027\u001b[0m     logging.warning(\n",
      "\u001b[0;31mValueError\u001b[0m: No gradients provided for any variable: ['sequential_3/discrete_autoregressive_flow/made/sequential/dense/kernel:0', 'sequential_3/discrete_autoregressive_flow/made/sequential/dense/bias:0', 'sequential_3/discrete_autoregressive_flow/made/sequential/dense_1/kernel:0', 'sequential_3/discrete_autoregressive_flow/made/sequential/dense_1/bias:0', 'sequential_3/discrete_autoregressive_flow/made/sequential/dense_2/kernel:0', 'sequential_3/discrete_autoregressive_flow/made/sequential/dense_2/bias:0', 'sequential_3/discrete_autoregressive_flow_1/made_1/sequential_1/dense_3/kernel:0', 'sequential_3/discrete_autoregressive_flow_1/made_1/sequential_1/dense_3/bias:0', 'sequential_3/discrete_autoregressive_flow_1/made_1/sequential_1/dense_4/kernel:0', 'sequential_3/discrete_autoregressive_flow_1/made_1/sequential_1/dense_4/bias:0', 'sequential_3/discrete_autoregressive_flow_1/made_1/sequential_1/dense_5/kernel:0', 'sequential_3/discrete_autoregressive_flow_1/made_1/sequential_1/dense_5/bias:0', 'sequential_3/discrete_autoregressive_flow_2/made_2/sequential_2/dense_6/kernel:0', 'sequential_3/discrete_autoregressive_flow_2/made_2/sequential_2/dense_6/bias:0', 'sequential_3/discrete_autoregressive_flow_2/made_2/sequential_2/dense_7/kernel:0', 'sequential_3/discrete_autoregressive_flow_2/made_2/sequential_2/dense_7/bias:0', 'sequential_3/discrete_autoregressive_flow_2/made_2/sequential_2/dense_8/kernel:0', 'sequential_3/discrete_autoregressive_flow_2/made_2/sequential_2/dense_8/bias:0']."
     ]
    }
   ],
   "source": [
    "flow.fit(oh, y, epochs=10, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features and then underscore tf.Tensor(\n",
      "[[[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]], shape=(32, 2, 150), dtype=float32) 0\n",
      "whitenend features tf.Tensor(\n",
      "[[[ 4.39087557e-08 -1.16304342e-07  1.81788209e-07 ... -1.47833745e-07\n",
      "    4.70543888e-08 -1.89775903e-07]\n",
      "  [-4.76837165e-08  4.61427518e-08  1.74542024e-07 ... -1.25894772e-07\n",
      "    7.95030033e-08  5.46614096e-08]]\n",
      "\n",
      " [[-5.08268704e-06 -7.65686679e-08 -1.07436868e-07 ... -4.60467620e-09\n",
      "    1.02714985e-07 -8.60671676e-08]\n",
      "  [-1.48614248e-07 -3.07907925e-07  8.86944008e-07 ... -8.70709016e-08\n",
      "   -8.00550204e-09  2.43305038e-07]]\n",
      "\n",
      " [[ 1.22189519e-07 -8.24203923e-08  7.32002192e-08 ... -3.71855791e-09\n",
      "   -4.41420234e-09 -6.77529144e-08]\n",
      "  [ 4.27961368e-07  5.86763491e-08 -1.89021648e-07 ...  3.27118990e-08\n",
      "    3.42697604e-08 -6.35871515e-08]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[-4.49021655e-08 -3.90040888e-08 -2.02621866e-08 ...  2.10560174e-07\n",
      "    1.01098308e-07  1.99560120e-07]\n",
      "  [ 1.00930535e-07 -9.10367106e-08 -2.78230132e-08 ... -1.66242017e-07\n",
      "    2.39627809e-07 -2.27517845e-07]]\n",
      "\n",
      " [[-4.49021655e-08 -3.90040888e-08 -2.02621866e-08 ...  2.10560174e-07\n",
      "    1.01098308e-07  1.99560120e-07]\n",
      "  [ 1.44640609e-07 -1.27103192e-07 -6.23913436e-08 ... -4.64021035e-08\n",
      "    5.53045680e-08 -7.79338478e-08]]\n",
      "\n",
      " [[-2.05636024e-08 -2.52723055e-07  4.02106117e-08 ... -3.34373766e-07\n",
      "   -2.71300650e-07  7.75172396e-07]\n",
      "  [-2.59478895e-07 -6.88555915e-08  6.05335970e-07 ... -1.14320136e-08\n",
      "    3.93860189e-09  1.69304172e-07]]], shape=(32, 2, 150), dtype=float32)\n",
      "tf.Tensor(5.311535, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "out = flow(oh[:batch_size])\n",
    "loss = loss_fn(0, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features and then underscore Tensor(\"discrete_autoregressive_flow_6/concat_1:0\", shape=(32, 2, 150), dtype=float32) 0\n",
      "whitenend features Tensor(\"Real_2:0\", shape=(32, 2, 150), dtype=float32)\n",
      "Tensor(\"Neg:0\", shape=(), dtype=float32)\n",
      "GRADIENTS [None, None, None, None, None, None]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features and then underscore tf.Tensor(\n",
      "[[[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]], shape=(32, 2, 150), dtype=float32) 0\n",
      "whitenend features tf.Tensor(\n",
      "[[[ 4.39087557e-08 -1.16304342e-07  1.81788209e-07 ... -1.47833745e-07\n",
      "    4.70543888e-08 -1.89775903e-07]\n",
      "  [-4.76837165e-08  4.61427518e-08  1.74542024e-07 ... -1.25894772e-07\n",
      "    7.95030033e-08  5.46614096e-08]]\n",
      "\n",
      " [[-5.08268704e-06 -7.65686679e-08 -1.07436868e-07 ... -4.60467620e-09\n",
      "    1.02714985e-07 -8.60671676e-08]\n",
      "  [-1.48614248e-07 -3.07907925e-07  8.86944008e-07 ... -8.70709016e-08\n",
      "   -8.00550204e-09  2.43305038e-07]]\n",
      "\n",
      " [[ 1.22189519e-07 -8.24203923e-08  7.32002192e-08 ... -3.71855791e-09\n",
      "   -4.41420234e-09 -6.77529144e-08]\n",
      "  [ 4.27961368e-07  5.86763491e-08 -1.89021648e-07 ...  3.27118990e-08\n",
      "    3.42697604e-08 -6.35871515e-08]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[-4.49021655e-08 -3.90040888e-08 -2.02621866e-08 ...  2.10560174e-07\n",
      "    1.01098308e-07  1.99560120e-07]\n",
      "  [ 1.00930535e-07 -9.10367106e-08 -2.78230132e-08 ... -1.66242017e-07\n",
      "    2.39627809e-07 -2.27517845e-07]]\n",
      "\n",
      " [[-4.49021655e-08 -3.90040888e-08 -2.02621866e-08 ...  2.10560174e-07\n",
      "    1.01098308e-07  1.99560120e-07]\n",
      "  [ 1.44640609e-07 -1.27103192e-07 -6.23913436e-08 ... -4.64021035e-08\n",
      "    5.53045680e-08 -7.79338478e-08]]\n",
      "\n",
      " [[-2.05636024e-08 -2.52723055e-07  4.02106117e-08 ... -3.34373766e-07\n",
      "   -2.71300650e-07  7.75172396e-07]\n",
      "  [-2.59478895e-07 -6.88555915e-08  6.05335970e-07 ... -1.14320136e-08\n",
      "    3.93860189e-09  1.69304172e-07]]], shape=(32, 2, 150), dtype=float32)\n",
      "tf.Tensor(5.311535, shape=(), dtype=float32)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "`loss` passed to Optimizer.compute_gradients should be a function when eager execution is enabled.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-0de1ecd1975e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGradientDescentOptimizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mminimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/ed2/lib/python3.7/site-packages/tensorflow_core/python/training/optimizer.py\u001b[0m in \u001b[0;36mminimize\u001b[0;34m(self, loss, global_step, var_list, gate_gradients, aggregation_method, colocate_gradients_with_ops, name, grad_loss)\u001b[0m\n\u001b[1;32m    401\u001b[0m         \u001b[0maggregation_method\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maggregation_method\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m         \u001b[0mcolocate_gradients_with_ops\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolocate_gradients_with_ops\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 403\u001b[0;31m         grad_loss=grad_loss)\n\u001b[0m\u001b[1;32m    404\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    405\u001b[0m     \u001b[0mvars_with_grad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mv\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgrads_and_vars\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mg\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ed2/lib/python3.7/site-packages/tensorflow_core/python/training/optimizer.py\u001b[0m in \u001b[0;36mcompute_gradients\u001b[0;34m(self, loss, var_list, gate_gradients, aggregation_method, colocate_gradients_with_ops, grad_loss)\u001b[0m\n\u001b[1;32m    479\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    480\u001b[0m       raise RuntimeError(\n\u001b[0;32m--> 481\u001b[0;31m           \u001b[0;34m\"`loss` passed to Optimizer.compute_gradients should \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    482\u001b[0m           \"be a function when eager execution is enabled.\")\n\u001b[1;32m    483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: `loss` passed to Optimizer.compute_gradients should be a function when eager execution is enabled."
     ]
    }
   ],
   "source": [
    "optimizer = tf.compat.v1.train.GradientDescentOptimizer(learning_rate=0.1).minimize(loss_fn(0, out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(flow.trainable_variables())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 2\n",
    "length = 4\n",
    "loc_only=False\n",
    "vocab_size = 5\n",
    "if loc_only:\n",
    "    units = vocab_size\n",
    "    network = ed.layers.MADE(units, [])\n",
    "else:\n",
    "    units = 2 * vocab_size\n",
    "    mask = tf.reshape([0] * vocab_size + [-1e10] + [0] * (vocab_size - 1),\n",
    "                    [1, 1, 2 * vocab_size])\n",
    "    network_ = ed.layers.MADE(units, [])\n",
    "    network = lambda inputs, **kwargs: mask + network_(inputs, **kwargs)\n",
    "base = ed.OneHotCategorical(logits=tf.random.normal([batch_size,\n",
    "                                                     length,\n",
    "                                                     vocab_size]),\n",
    "                            dtype=tf.float32)\n",
    "flow = ed.layers.DiscreteAutoregressiveFlow(network, 1.)\n",
    "flow_rv = flow(base)\n",
    "\n",
    "\n",
    "#flow.evaluate(tf1.global_variables_initializer())\n",
    "#res = flow.evaluate(flow_rv)\n",
    "\n",
    "\n",
    "inputs = np.random.randint(0, vocab_size - 1, size=(batch_size, length))\n",
    "inputs = tf.one_hot(inputs, depth=vocab_size, dtype=tf.float32)\n",
    "outputs = flow(inputs)\n",
    "rev_outputs = flow.reverse(outputs)\n",
    "#inputs_val, rev_outputs_val = #([inputs, rev_outputs])\n",
    "\n",
    "\n",
    "inputs_log_prob = base.distribution.log_prob(inputs)\n",
    "outputs_log_prob = flow_rv.distribution.log_prob(outputs)\n",
    "#res1, res2 = self.evaluate([inputs_log_prob, outputs_log_prob])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'tensorflow.python.framework.ops.EagerTensor' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-e63d1744104c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     27\u001b[0m       logits=flow_rv.distribution.base.logits))\n\u001b[1;32m     28\u001b[0m \u001b[0;31m#grads = tape.gradient(loss, network_.trainable_weights)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mminimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnetwork_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m '''self.evaluate(tf1.global_variables_initializer())\n\u001b[1;32m     31\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ed2/lib/python3.7/site-packages/tensorflow_core/python/keras/optimizer_v2/optimizer_v2.py\u001b[0m in \u001b[0;36mminimize\u001b[0;34m(self, loss, var_list, grad_loss, name)\u001b[0m\n\u001b[1;32m    315\u001b[0m     \"\"\"\n\u001b[1;32m    316\u001b[0m     grads_and_vars = self._compute_gradients(\n\u001b[0;32m--> 317\u001b[0;31m         loss, var_list=var_list, grad_loss=grad_loss)\n\u001b[0m\u001b[1;32m    318\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads_and_vars\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ed2/lib/python3.7/site-packages/tensorflow_core/python/keras/optimizer_v2/optimizer_v2.py\u001b[0m in \u001b[0;36m_compute_gradients\u001b[0;34m(self, loss, var_list, grad_loss)\u001b[0m\n\u001b[1;32m    349\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    350\u001b[0m         \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 351\u001b[0;31m       \u001b[0mloss_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    352\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m       \u001b[0mvar_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvar_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'tensorflow.python.framework.ops.EagerTensor' object is not callable"
     ]
    }
   ],
   "source": [
    "batch_size = 2\n",
    "length = 4\n",
    "vocab_size = 2\n",
    "loc_only = True\n",
    "\n",
    "opt = tf.keras.optimizers.SGD(learning_rate=0.1)\n",
    "\n",
    "if loc_only:\n",
    "  units = vocab_size\n",
    "  network_ = ed.layers.MADE(units, [16, 16])\n",
    "  network = network_\n",
    "else:\n",
    "  units = 2 * vocab_size\n",
    "  network_ = ed.layers.MADE(units, [16, 16])\n",
    "  mask = tf.reshape([0] * vocab_size + [-1e10] + [0] * (vocab_size - 1),\n",
    "                    [1, 1, 2 * vocab_size])\n",
    "  network = lambda inputs, **kwargs: mask + network_(inputs, **kwargs)\n",
    "with tf.GradientTape() as tape:\n",
    "  base = ed.OneHotCategorical(\n",
    "      logits=tf.random.normal([batch_size, length, vocab_size]))\n",
    "  flow = ed.layers.DiscreteAutoregressiveFlow(network, 1.)\n",
    "  flow_rv = flow(base)\n",
    "  features = np.random.randint(0, vocab_size - 1, size=(batch_size, length))\n",
    "  features = tf.one_hot(features, depth=vocab_size, dtype=tf.float32)\n",
    "  loss = tf.reduce_sum(tf.nn.softmax_cross_entropy_with_logits(\n",
    "      labels=flow.reverse(features),\n",
    "      logits=flow_rv.distribution.base.logits))\n",
    "grads = tape.gradient(loss, network_.trainable_weights)\n",
    "opt.minimize(loss, network_.trainable_weights)\n",
    "'''self.evaluate(tf1.global_variables_initializer())\n",
    "_ = self.evaluate(grads)\n",
    "for grad in grads:\n",
    "  self.assertIsNotNone(grad)'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'UnreadVariable' shape=() dtype=int64, numpy=1>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "batch_size = 2\n",
    "length = 4\n",
    "vocab_size = 2\n",
    "loc_only = True\n",
    "\n",
    "opt = tf.keras.optimizers.SGD(learning_rate=0.1)\n",
    "\n",
    "if loc_only:\n",
    "  units = vocab_size\n",
    "  network_ = ed.layers.MADE(units, [16, 16])\n",
    "  network = network_\n",
    "else:\n",
    "  units = 2 * vocab_size\n",
    "  network_ = ed.layers.MADE(units, [16, 16])\n",
    "  mask = tf.reshape([0] * vocab_size + [-1e10] + [0] * (vocab_size - 1),\n",
    "                    [1, 1, 2 * vocab_size])\n",
    "  network = lambda inputs, **kwargs: mask + network_(inputs, **kwargs)\n",
    "    \n",
    "base = ed.OneHotCategorical(\n",
    "logits=tf.random.normal([batch_size, length, vocab_size]))\n",
    "flow = ed.layers.DiscreteAutoregressiveFlow(network, 1.)\n",
    "flow_rv = flow(base)\n",
    "features = np.random.randint(0, vocab_size - 1, size=(batch_size, length))\n",
    "features = tf.one_hot(features, depth=vocab_size, dtype=tf.float32)\n",
    "with tf.GradientTape() as tape:\n",
    "    loss = tf.reduce_sum(tf.nn.softmax_cross_entropy_with_logits(\n",
    "        labels=flow.reverse(features),\n",
    "        logits=flow_rv.distribution.base.logits))\n",
    "grads = tape.gradient(loss, network_.trainable_weights)\n",
    "opt.apply_gradients(zip(grads,network_.trainable_weights))\n",
    "#opt.minimize(loss, network_.trainable_weights)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=23497, shape=(2, 4), dtype=float32, numpy=\n",
       "array([[-4.1944447 , -1.7323816 , -0.9144609 , -3.8651865 ],\n",
       "       [-1.5306695 , -0.93880343, -2.4575806 , -1.8257781 ]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base.distribution.log_prob(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 4 5\n"
     ]
    }
   ],
   "source": [
    "print(batch_size,\n",
    "                                                     length,\n",
    "                                                     vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=23263, shape=(2, 4, 5), dtype=float32, numpy=\n",
       "array([[[ 3.57627883e-08,  5.22515613e-08,  1.02429908e-07,\n",
       "          9.99999702e-01,  1.19987362e-07],\n",
       "        [-3.57627883e-08,  6.89621649e-09,  9.99999821e-01,\n",
       "          8.45745518e-08,  5.60555691e-08],\n",
       "        [ 1.07288365e-07,  9.99999702e-01,  1.23809542e-07,\n",
       "         -1.26952484e-08,  1.49860625e-07],\n",
       "        [-3.57627883e-08,  6.89621649e-09,  9.99999821e-01,\n",
       "          8.45745518e-08,  5.60555691e-08]],\n",
       "\n",
       "       [[ 7.45058060e-08,  9.99999702e-01,  3.16178870e-08,\n",
       "          1.62374540e-08,  6.92420130e-08],\n",
       "        [ 3.57627883e-08,  5.22515613e-08,  1.02429908e-07,\n",
       "          9.99999702e-01,  1.19987362e-07],\n",
       "        [ 5.96046457e-09,  1.09662913e-07,  9.99999702e-01,\n",
       "          1.23093386e-07,  4.76912412e-08],\n",
       "        [ 5.06639495e-08,  9.99999821e-01, -6.92426727e-10,\n",
       "          1.56020747e-07,  1.22815225e-08]]], dtype=float32)>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rev_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "perm = tf.math.floormod(\n",
    "        tf.tile(tf.range(vocab_size)[:, tf.newaxis], [1, vocab_size]) *\n",
    "        tf.range(vocab_size)[tf.newaxis], vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([150, 150])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=802880, shape=(150, 150, 150), dtype=float32, numpy=\n",
       "array([[[1., 0., 0., ..., 0., 0., 0.],\n",
       "        [1., 0., 0., ..., 0., 0., 0.],\n",
       "        [1., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [1., 0., 0., ..., 0., 0., 0.],\n",
       "        [1., 0., 0., ..., 0., 0., 0.],\n",
       "        [1., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[1., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 1., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 1., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 1., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 1., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 1.]],\n",
       "\n",
       "       [[1., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 1., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 1., 0.]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[1., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 1., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[1., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 1., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 1., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[1., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 1.],\n",
       "        [0., 0., 0., ..., 0., 1., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 1., ..., 0., 0., 0.],\n",
       "        [0., 1., 0., ..., 0., 0., 0.]]], dtype=float32)>"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.one_hot(perm, depth=vocab_size, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=802836, shape=(150, 150), dtype=int32, numpy=\n",
       "array([[  0,   0,   0, ...,   0,   0,   0],\n",
       "       [  1,   1,   1, ...,   1,   1,   1],\n",
       "       [  2,   2,   2, ...,   2,   2,   2],\n",
       "       ...,\n",
       "       [147, 147, 147, ..., 147, 147, 147],\n",
       "       [148, 148, 148, ..., 148, 148, 148],\n",
       "       [149, 149, 149, ..., 149, 149, 149]], dtype=int32)>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.tile(tf.range(vocab_size)[:, tf.newaxis], [1, vocab_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=802855, shape=(150, 150), dtype=int32, numpy=\n",
       "array([[    0,     0,     0, ...,     0,     0,     0],\n",
       "       [    0,     1,     2, ...,   147,   148,   149],\n",
       "       [    0,     2,     4, ...,   294,   296,   298],\n",
       "       ...,\n",
       "       [    0,   147,   294, ..., 21609, 21756, 21903],\n",
       "       [    0,   148,   296, ..., 21756, 21904, 22052],\n",
       "       [    0,   149,   298, ..., 21903, 22052, 22201]], dtype=int32)>"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.tile(tf.range(vocab_size)[:, tf.newaxis], [1, vocab_size]) * tf.range(vocab_size)[tf.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  0,   0,   0,  ...,   0,   0,   0],\n",
       "        [  1,   1,   1,  ...,   1,   1,   1],\n",
       "        [  2,   2,   2,  ...,   2,   2,   2],\n",
       "        ...,\n",
       "        [147, 147, 147,  ..., 147, 147, 147],\n",
       "        [148, 148, 148,  ..., 148, 148, 148],\n",
       "        [149, 149, 149,  ..., 149, 149, 149]])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.arange(vocab_size).unsqueeze(1).repeat(1,vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.arange(vocab_size).unsqueeze(1).repeat(1,vocab_size) * torch.arange(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[    0,     0,     0,  ...,     0,     0,     0],\n",
       "        [    0,     1,     2,  ...,   147,   148,   149],\n",
       "        [    0,     2,     4,  ...,   294,   296,   298],\n",
       "        ...,\n",
       "        [    0,   147,   294,  ..., 21609, 21756, 21903],\n",
       "        [    0,   148,   296,  ..., 21756, 21904, 22052],\n",
       "        [    0,   149,   298,  ..., 21903, 22052, 22201]])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def floorMod(a,b):\n",
    "    return a - (torch.floor(torch.div(a,b).float())*b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "perm= floorMod(a, vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = torch.zeros((150*150,150))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_f = perm.flatten().long().unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([22500, 150])"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oh = z.scatter_(1,p_f,1)\n",
    "oh.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [1., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [1., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [1., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [1., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [1., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "        [[1., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 1., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 1.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 1., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 1., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 1.]],\n",
       "\n",
       "        [[1., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 1.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 1., 0.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[1., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 1., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "        [[1., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 1., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 1.,  ..., 0., 0., 0.]],\n",
       "\n",
       "        [[1., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 1.],\n",
       "         [0., 0., 0.,  ..., 0., 1., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 1.,  ..., 0., 0., 0.],\n",
       "         [0., 1., 0.,  ..., 0., 0., 0.]]])"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oh.view(150,150,150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'layer = MADE(vocab_size, [nh, nh, nh], vocab_size, num_masks=1, natural_ordering=True)\\nmodel = DiscreteAutoregressiveFlow( layer, temperature, vocab_size )'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nh = 24\n",
    "vocab_size = 150\n",
    "temperature = 0.1\n",
    "\n",
    "network = ed.layers.MADE(vocab_size, hidden_dims=[nh,nh,nh, vocab_size*2])\n",
    "model = ed.layers.DiscreteAutoregressiveFlow(network, temperature)\n",
    "\n",
    "'''layer = MADE(vocab_size, [nh, nh, nh], vocab_size, num_masks=1, natural_ordering=True)\n",
    "model = DiscreteAutoregressiveFlow( layer, temperature, vocab_size )'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "for l in network.network.layers:\n",
    "    print(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400, 2, 150)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oh.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'layer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-905b953c8bce>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moh\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mvocab_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'layer' is not defined"
     ]
    }
   ],
   "source": [
    "layer.forward(torch.tensor(oh[:64,:,:vocab_size]).float()).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[82, 86],\n",
       "       [81, 93],\n",
       "       [74, 88],\n",
       "       [79, 89],\n",
       "       [81, 92],\n",
       "       [82, 82],\n",
       "       [80, 86],\n",
       "       [79, 85],\n",
       "       [79, 91],\n",
       "       [80, 88],\n",
       "       [75, 92],\n",
       "       [77, 90],\n",
       "       [76, 93],\n",
       "       [78, 86],\n",
       "       [78, 89],\n",
       "       [76, 82],\n",
       "       [85, 91],\n",
       "       [78, 88],\n",
       "       [80, 87],\n",
       "       [78, 91],\n",
       "       [82, 93],\n",
       "       [81, 90],\n",
       "       [78, 90],\n",
       "       [74, 91],\n",
       "       [81, 87],\n",
       "       [87, 92],\n",
       "       [82, 91],\n",
       "       [79, 88],\n",
       "       [79, 86],\n",
       "       [80, 97],\n",
       "       [81, 95],\n",
       "       [76, 96],\n",
       "       [81, 96],\n",
       "       [75, 88],\n",
       "       [80, 88],\n",
       "       [73, 89],\n",
       "       [87, 88],\n",
       "       [78, 89],\n",
       "       [80, 94],\n",
       "       [76, 88],\n",
       "       [77, 89],\n",
       "       [81, 94],\n",
       "       [75, 89],\n",
       "       [80, 95],\n",
       "       [76, 87],\n",
       "       [81, 84],\n",
       "       [74, 91],\n",
       "       [78, 91],\n",
       "       [74, 95],\n",
       "       [83, 89],\n",
       "       [19,  4],\n",
       "       [18,  5],\n",
       "       [25, 11],\n",
       "       [19,  5],\n",
       "       [23, 15],\n",
       "       [19, 11],\n",
       "       [18,  8],\n",
       "       [24,  4],\n",
       "       [21,  5],\n",
       "       [25,  6],\n",
       "       [24, 10],\n",
       "       [18,  9],\n",
       "       [20,  7],\n",
       "       [20, 11]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oh[:64,:,:vocab_size].argmax(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer made_6 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=1993, shape=(150,), dtype=bool, numpy=\n",
       "array([False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False])>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network( oh[:64,:,:vocab_size] )[0,0,:] == network( oh[:64,:,:vocab_size] )[0,1,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer discrete_autoregressive_flow_6 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=3045, shape=(64, 2, 150), dtype=float32, numpy=\n",
       "array([[[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]]], dtype=float32)>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model( oh[:64,:,:vocab_size] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(10, dtype=torch.int32)"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(10).type(torch.int32)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ed2",
   "language": "python",
   "name": "ed2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
